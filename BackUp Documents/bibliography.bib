@article{Schafer2002,
abstract = {Statistical procedures for missing data have vastly improved, yet misconception and unsound practice still abound. The authors frame the missing-data problem, review methods offer advice, and raise issues that remain unresolved. They clear up common misunderstandings regarding the missing at random (MAR) concept. They summarize the evidence against older procedures and, with few exceptions, discourage their use. They present, in both technical and practical language, 2 general approaches that come highly recommended: maximum likelihood (ML) and Bayesian multiple imputation (MI). Newer developments are discussed, including some for dealing with missing data that are not MAR. Although not yet in the mainstream, these procedures may eventually extend the ML and MI methods that currently represent the state of the art.},
author = {Schafer, Joseph L. and Graham, John W.},
doi = {10.1037/1082-989X.7.2.147},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Schafer{\&}Graham2002.pdf:pdf},
issn = {1939-1463},
journal = {Psychological Methods},
number = {2},
pages = {147--177},
pmid = {12090408},
title = {{Missing data: Our view of the state of the art.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.7.2.147},
volume = {7},
year = {2002}
}
@misc{Meng2011,
author = {Meng, Xuan-Yu and Zhang, Hong-Xing and Cui, Mihaly Mezei and Meng},
booktitle = {Current Computer-Aided Drug Design},
doi = {http://dx.doi.org/10.2174/157340911795677602},
isbn = {1573-4099/1875-6697},
keywords = {Conformational sampling,QSAR,backbone flexibility,drug discovery,flexible protein-ligand docking,high throughput screening,local move Monte Carlo sampling,molecular docking,scoring,virtual screening},
number = {2},
pages = {146--157},
title = {{Molecular Docking: A Powerful Approach for Structure-Based Drug Discovery}},
url = {http://www.eurekaselect.com/node/74117/article},
volume = {7},
year = {2011}
}
@article{Martin2019,
abstract = {Profile-QSAR (pQSAR) is a massively multi-task, 2-step machine learning method with unprecedented scope, accuracy and applicability domain. In step one, a “profile” of conventional single-assay random forest regression (RFR) models are trained on a very large number of biochemical and cellular pIC50 assays using Morgan 2 sub-structural fingerprints as compound descriptors. In step two, a panel of PLS models are built using the profile of pIC50 predictions from those RFR models as compound descriptors. Hence the name. Previously described for a panel of 728 biochemical and cellular kinase assays, we have now built an enormous pQSAR from 11,805 diverse Novartis IC50 and EC50 assays. This large number of assays, and hence of compound descriptors for PLS, dictated reducing the profile by only including RFR models whose predictions correlate with the assay being modeled. The RFR and pQSAR models were evaluated with our “realistically novel” held-out test set whose median average similarity to the nearest training set member across the 11,805 assays was only 0.34, thus testing a realistically large applicability domain. For the 11,805 single-assay RFR models, the median correlation of prediction with experiment was only R 2 ext=0.05, virtually random, and only 8{\%} of the models achieved our standard success threshold of R 2 ext=0.30. For pQSAR, the median correlation was R 2 ext=0.53, comparable to 4-concentration experimental IC50s, and 72{\%} of the models met our R 2 ext{\textgreater}0.30 standard, totaling 8558 successful models. The successful models included assays from all of the 51 annotated target sub-classes, as well as 4196 phenotypic assays, indicating that pQSAR can be applied to virtually any disease area. Every month, all models are updated to include new measurements, and predictions are made for 5.5 million Novartis compounds, totaling 50 billion predictions. Common uses have included virtual screening, selectivity design, toxicity and promiscuity prediction, mechanism-of-action prediction, and others.},
author = {Martin, Eric J and Polyakov, Valery R and Zhu, Xiang-Wei and Mukherjee, Prasenjit and Tian, Li and Liu, Xin},
doi = {10.1101/620864},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/620864.full.pdf:pdf},
journal = {bioRxiv},
number = {4218},
pages = {620864},
title = {{All-Assay-Max2 pQSAR: Activity predictions as accurate as 4-concentration IC50s for 8,558 Novartis assays}},
url = {https://www.biorxiv.org/content/10.1101/620864v2},
year = {2019}
}
@book{Gondara2018,
abstract = {Mining of Evolving Data Streams with Privacy Preservation 1 Philip S. Yu Data Mining Grand Challenges 2 Usama Fayyad Session 1A: Classification (I) Evaluating the Replicability of Significance Tests for Comparing Learning Algorithms 3 Remco R. Bouckaert, Eibe Frank Spectral Energy Minimization for Semi-supervised Learning 13 Chun-hung Li, Zhi-li Wu Discriminative Methods for Multi-labeled Classification 22 Shantanu Godbole, Sunita Sarawagi Session 1B: Clustering (I) Subspace Clustering of High Dimensional Spatial Data with Noises 31 Chih-Ming Hsu, Ming-Syan Chen Constraint-Based Graph Clustering through Node Sequencing and Partitioning 41 Yu Qian, Kang Zhang, Wei Lai Mining Expressive Process Models by Clustering Workflow Traces 52 Gianluigi Greco, Antonella Guzzo, Luigi Pontieri, Domenico Sacc{\`{a}} Session 1C: Association Rules (I) CMTreeMiner: Mining Both Closed and Maximal Frequent Subtrees 63 Yun Chi, Yirong Yang, Yi Xia, Richard R. Muntz Secure Association Rule Sharing 74 Stanley R.M. Oliveira, Osmar R. Za{\"{i}}ane, Y{\"{u}}cel Saygin Self-Similar Mining of Time Association Rules 86 Daniel Barbar{\'{a}}, Ping Chen, Zohreh Nazeri Session 2A: Novel Algorithms (I) ParaDualMiner: An Efficient Parallel Implementation of the DualMiner Algorithm 96 Roger M.H. Ting, James Bailey, Kotagiri Ramamohanarao A Novel Distributed Collaborative Filtering Algorithm and Its Implementation on P2P Overlay Network 106 Peng Han, Bo Xie, Fan Yang, Jiajun Wang, Ruimin Shen An Efficient Algorithm for Dense Regions Discovery from Large-Scale Data Streams 116 Andy M. Yip, Edmond H. Wu, Michael K. Ng, Tony F. Chan Blind Data Linkage Using Similarity Comparisons 121 Tim Churches, Peter Christen Condensed Representation of Emerging Patterns 127 Arnaud Soulet, Bruno Cr{\'{e}}milleux, Fran{\c{c}}ois Rioult Session 2B: Association (II) Discovery of Maximally Frequent Tag Tree Patterns with Contractible Variables from Semistructured Documents 133 Tetsuhiro Miyahara, Yusuke Suzuki, Takayoshi Shoudai, Tomoyuki Uchida, Kenichi Takahashi, Hiroaki Ueda Mining Term Association Rules for Heuristic Query Construction 145 Zhenxing Qin, Li Liu, Shichao Zhang FP-Bonsai: The Art of Growing and Pruning Small FP-Trees 155 Francesco Bonchi, Bart Goethals Mining Negative Rules Using GRD 161 Dhananjay R. Thiruvady, Geoff I. Webb Applying Association Rules for Interesting Recommendations Using Rule Templates 166 Jiye Li, Bin Tang, Nick Cercone Session 2C: Classification (II) Feature Extraction and Classification System for Nonlinear and Online Data 171 Byung Joo Kim, Il Kon Kim, Kwang Baek Kim A Metric Approach to Building Decision Trees Based on Goodman-Kruskal Association Index 181 Dan A. Simovici, Szymon Jaroszewicz DRC-BK: Mining Classification Rules with Help of SVM 191 Yang Zhang, Zhanhuai Li, Yan Tang, Kebin Cui A New Data Mining Method Using Organizational Coevolutionary Mechanism 196 Jing Liu, Weicai Zhong, Fang Liu, Licheng Jiao Noise Tolerant Classification by Chi Emerging Patterns 201 Hongjian Fan, Kotagiri Ramamohanarao The Application of Emerging Patterns for Improving the Quality of Rare-Class Classification 207 Hamad Alhammady, Kotagiri Ramamohanarao Session 3A: Event Mining, Anomaly Detection, and Intrusion Detection Finding Negative Event-Oriented Patterns in Long Temporal Sequences 212 Xingzhi Sun, Maria E. Orlowska, Xue Li OBE: Outlier by Example 222 Cui Zhu, Hiroyuki Kitagawa, Spiros Papadimitriou, Christos Faloutsos Temporal Sequence Associations for Rare Events 235 Jie Chen, Hongxing He, Graham Williams, Huidong Jin Summarization of Spacecraft Telemetry Data by Extracting Significant Temporal Patterns 240 Takehisa Yairi, Shiro Ogasawara, Koichi Hori, Shinichi Nakasuka, Naoki Ishihama An Extended Negative Selection Algorithm for Anomaly Detection Xiaoshu Hang, Honghua Dai Adaptive Clustering for Network Intrusion Detection Joshua Oldmeadow, Siddarth Ravinutala, Christopher Leckie Session 3B: Ensemble Learning Ensembling MML Causal Discovery Honghua Dai, Gang Li, Zhi-Hua Zhou Logistic Regression and Boosting for Labeled Bags of Instances Xin Xu, Eibe Frank Fast and Light Boosting for Adaptive Mining of Data Streams Fang Chu, Carlo Zaniolo 282 Compact Dual Ensembles for Active Learning Amit Mandvikar, Huan Liu, Hiroshi Motoda On the Size of Training Set and the Benefit from Ensemble Zhi-Hua Zhou, Dan Wei, Gang Li, Honghua Dai Session 3C: Bayesian Network and Graph Mining Identifying Markov Blankets Using Lasso Estimation Gang Li, Honghua Dai, Yiqing Tu Selective Augmented Bayesian Network Classifiers Based on Rough Set Theory Zhihai Wang, Geoffrey I. Webb, Fei Zheng Using Self-Consistent Naive-Bayes to Detect Masquerades Kwong H. Yung DB-Subdue: Database Approach to Graph Mining Sharma Chakravarthy, Ramji Beera, Ramanathan Balachandran Session 3D: Text Mining (I) Finding Frequent Structural Features among Words in Tree-Structured Documents Tomoyuki Uchida, Tomonori Mogawa, Yasuaki Nakamura Exploring Potential of Leave-One-Out Estimator for Calibration of SVM in Text Mining Adam Kowalczyk, Bhavani Raskutti, Herman Ferr{\'{a}} Classifying Text Streams in the Presence of Concept Drifts Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Hongjun Lu Using Cluster-Based Sampling to Select Initial Training Set for Active Learning in Text Classification Jaeho Kang, Kwang Ryel Ryu, Hyuk-Chul Kwon Spectral Analysis of Text Collection for Similarity-Based Clustering Wenyuan Li, Wee-Keong Ng, Ee-Peng Lim Session 4A: Clustering (II) Clustering Multi-represented Objects with Noise Karin Kailing, Hans-Peter Kriegel, Alexey Pryakhin, Matthias Schubert Providing Diversity in K-Nearest Neighbor Query Results Anoop Jain, Parag Sarda, Jayant R. Haritsa 404 Cluster Structure of K-means Clustering via Principal Component Analysis Chris Ding, Xiaofeng He Combining Clustering with Moving Sequential Pattern Mining: A Novel and Efficient Technique Shuai Ma, Shiwei Tang, Dongqing Yang, Tengjiao Wang, Jinqiang Han An Alternative Methodology for Mining Seasonal Pattern Using Self-Organizing Map Denny Lee, Vincent C.S. Lee Session 4B: Association (III) ISM: Item Selection for Marketing with Cross-Selling Considerations Raymond Chi-Wing Wong, Ada Wai-Chee Fu Efficient Pattern-Growth Methods for Frequent Tree Pattern Mining Chen Wang, Mingsheng Hong, Jian Pei, Haofeng Zhou, Wei Wang, Baile Shi Mining Association Rules from Structural Deltas of Historical XML Documents Ling Chen, Sourav S. Bhowmick, Liang-Tien Chia Data Mining Proxy: Serving Large Number of Users for Efficient Frequent Itemset Mining Zhiheng Li, Jeffrey Xu Yu, Hongjun Lu, Yabo Xu, Guimei Liu Session 4C: Novel Algorithms (II) Formal Approach and Automated Tool for Translating ER Schemata into OWL Ontologies Zhuoming Xu, Xiao Cao, Yisheng Dong, Wenping Su Separating Structure from Interestingness Taneli Mielik{\"{a}}inen Exploiting Recurring Usage Patterns to Enhance Filesystem and Memory Subsystem Performance Benjamin Rutt, Srinivasan Parthasarathy Session 4D: Multimedia Mining Automatic Text Extraction for Content-Based Image Indexing Keechul Jung, Eun Yi Kim Peculiarity Oriented Analysis in Multi-people Tracking Images Muneaki Ohshima, Ning Zhong, Y. Y. Yao, Shinichi Murata 508 AutoSplit: Fast and Scalable Discovery of Hidden Variables in Stream and Multimedia Databases Jia- Yu Pan, Hiroyuki Kitagawa, Christos Faloutsos, Masafumi Hamamoto Session 5A: Text Mining and Web Mining (II) Semantic Sequence Kin: A Method of Document Copy Detection Jun-Peng Bao, Jun- Yi Shen, Xiao-Dong Liu, Hai- Yan Liu, Xiao-Di Zhang Extracting Citation Metadata from Online Publication Lists Using BLAST I-Ane Huang, Jan-Ming Ho, Hung-Yu Kao, Wen-Chang Lin Mining of Web-Page Visiting Patterns with Continuous-Time Markov Models Qiming Huang, Qiang Yang, Joshua Zhexue Huang, Michael K. Ng Discovering Ordered Tree Patterns from XML Queries Yi Chen Predicting Web Requests Efficiently Using a Probability Model Shanchan Wu, Wenyuan Wang Session 5B: Statistical Methods, Sequential Data Mining, and Time Series Mining CCMine: Efficient Mining of Confidence-Closed Correlated Patterns Won-Young Kim, Young-Koo Lee, Jiawei Han A Conditional Probability Distribution-Based Dissimilarity Measure for Categorial Data Le Si Quang, Ho Tu Bao Learning Hidden Markov Model Topology Based on KL Divergence for Information Extraction Kwok-Chung Au, Kwok-Wai Cheung A Non-parametric Wavelet Feature Extractor for Time Series Classification Hui Zhang, Tu Bao Ho, Mao Song Lin Rules Discovery from Cross-Sectional Short-Length Time Series Kedong Luo, Jianmin Wang, Jiaguang Sun 604 Session 5C: Novel Algorithms (III) Constraint-Based Mining of Formal Concepts in Transactional Data J{\'{e}}r{\'{e}}my Besson, C{\'{e}}line Robardet, Jean-Fran{\c{c}}ois Boulicaut Towards Optimizing Conjunctive Inductive Queries Johannes Fischer, Luc De Raedt Febrl – A Parallel Open Source Data Linkage System Peter Christen, Tim Churches, Markus Hegland A General Coding Method for Error-Correcting Output Codes Yan-huang Jiang, Qiang-li Zhao, Xue-jun Yang Discovering Partial Periodic Patterns in Discrete Data Sequences Huiping Cao, David W. Cheung, Nikos Mamoulis Session 5D: Biomedical Mining Conceptual Mining of Large Administrative Health Data Tatiana Semenova, Markus Hegland, Warwick Graco, Graham Williams A Semi-automatic System for Tagging Specialized Corpora Ahmed Amrani, Yves Kodratoff, Oriane Matte-Tailliez A Tree-Based Approach to the Discovery of Diagnostic Biomarkers for Ovarian Cancer Jinyan Li, Kotagiri Ramamohanarao A Novel Parameter-Less Clustering Method for Mining Gene Expression Data Vincent Shin-Mu Tseng, Ching-Pin Kao Extracting and Explaining Biological Knowledge in Microarray Data Paul J. Kennedy, Simeon J. Simoff, David Skillicorn, Daniel Catchpoole Further Applications of a Particle Visualization Framework Ke Yin, Ian Davidson Author Index 711},
address = {Cham},
author = {Gondara, Lovedeep and Wang, Ke},
doi = {10.1007/978-3-319-93040-4},
editor = {Phung, Dinh and Tseng, Vincent S. and Webb, Geoffrey I. and Ho, Bao and Ganji, Mohadeseh and Rashidi, Lida},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Gondara-Wang2018{\_}Chapter{\_}MIDAMultipleImputationUsingDen.pdf:pdf},
isbn = {978-3-319-93039-8},
pages = {260--272},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Advances in Knowledge Discovery and Data Mining}},
url = {http://link.springer.com/10.1007/b97861 http://link.springer.com/10.1007/978-3-319-93040-4},
volume = {10939},
year = {2018}
}
@article{Whitehead2019a,
author = {Whitehead, T. M. and Irwin, B. W. J. and Hunt, P. and Segall, M. D. and Conduit, G. J.},
doi = {10.1021/acs.jcim.8b00768},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {mar},
number = {3},
pages = {1197--1204},
title = {{Imputation of Assay Bioactivity Data Using Deep Learning}},
url = {https://pubs.acs.org/doi/10.1021/acs.jcim.8b00768},
volume = {59},
year = {2019}
}
@article{DeCao2018,
abstract = {Deep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is possible to side-step expensive search procedures in the discrete and vast space of chemical structures. We introduce MolGAN, an implicit, likelihood-free generative model for small molecular graphs that circumvents the need for expensive graph matching procedures or node ordering heuristics of previous likelihood-based methods. Our method adapts generative adversarial networks (GANs) to operate directly on graph-structured data. We combine our approach with a reinforcement learning objective to encourage the generation of molecules with specific desired chemical properties. In experiments on the QM9 chemical database, we demonstrate that our model is capable of generating close to 100{\%} valid compounds. MolGAN compares favorably both to recent proposals that use string-based (SMILES) representations of molecules and to a likelihood-based method that directly generates graphs, albeit being susceptible to mode collapse.},
archivePrefix = {arXiv},
arxivId = {1805.11973},
author = {{De Cao}, Nicola and Kipf, Thomas},
eprint = {1805.11973},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1805.11973.pdf:pdf},
month = {may},
title = {{MolGAN: An implicit generative model for small molecular graphs}},
url = {http://arxiv.org/abs/1805.11973},
year = {2018}
}
@misc{,
keywords = {Daylight,SMARTS},
mendeley-tags = {Daylight,SMARTS},
title = {{Daylight SMARTS}},
url = {https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html},
urldate = {2019-12-16}
}
@article{Bergstra2015,
abstract = {{\textcopyright} 2015 IOP Publishing Ltd. Sequential model-based optimization (also known as Bayesian optimization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for performing hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. This paper also gives an overview of Hyperopt-Sklearn, a software project that provides automatic algorithm configuration of the Scikit-learn machine learning library. Following Auto-Weka, we take the view that the choice of classifier and even the choice of preprocessing module can be taken together to represent a single large hyperparameter optimization problem. We use Hyperopt to define a search space that encompasses many standard components (e.g. SVM, RF, KNN, PCA, TFIDF) and common patterns of composing them together. We demonstrate, using search algorithms in Hyperopt and standard benchmarking data sets (MNIST, 20-newsgroups, convex shapes), that searching this space is practical and effective. In particular, we improve on best-known scores for the model space for both MNIST and convex shapes. The paper closes with some discussion of ongoing and future work.},
author = {Bergstra, James and Komer, Brent and Eliasmith, Chris and Yamins, Dan and Cox, David D.},
doi = {10.1088/1749-4699/8/1/014008},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Bergstra{\_}2015{\_}Comput.{\_}Sci.{\_}Disc.{\_}8{\_}014008.pdf:pdf},
issn = {17494699},
journal = {Computational Science and Discovery},
keywords = {Bayesian optimization,Python,Scikit-learn,machine learning},
number = {1},
publisher = {IOP Publishing},
title = {{Hyperopt: A Python library for model selection and hyperparameter optimization}},
volume = {8},
year = {2015}
}
@inproceedings{Tracey2018,
abstract = {Gaussian process priors are commonly used in aerospace design for performing Bayesian optimization. Nonetheless, Gaussian processes suffer two significant drawbacks: outliers are a priori assumed unlikely, and the posterior variance conditioned on observed data depends only on the locations of those data, not the associated sample values. Student's-T processes are a generalization of Gaussian processes, founded on the Student's-T distribution instead of the Gaussian distribution. Student's-T processes maintain the primary advantages of Gaussian processes (kernel function, analytic update rule) with additional benefits beyond Gaussian processes. The Student's-T distribution has higher Kurtosis than a Gaussian distribution and so outliers are much more likely, and the posterior variance increases or decreases depending on the variance of observed data sample values. Here, we describe Student's-T processes, and discuss their advantages in the context of aerospace optimization. We show how to construct a Student's-T process using a kernel function and how to update the process given new samples. We provide a clear derivation of optimization-relevant quantities such as expected improvement, and contrast with the related computations for Gaussian processes. Finally, we compare the performance of Student's-T processes against Gaussian process on canonical test problems in Bayesian optimization, and apply the Student's-T process to the optimization of an aerostructural design problem.},
address = {Reston, Virginia},
archivePrefix = {arXiv},
arxivId = {1801.06147},
author = {Tracey, Brendan D and Wolpert, David},
booktitle = {2018 AIAA Non-Deterministic Approaches Conference},
doi = {10.2514/6.2018-1659},
eprint = {1801.06147},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1801.06147.pdf:pdf},
isbn = {978-1-62410-529-6},
month = {jan},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Upgrading from Gaussian Processes to Student's-T Processes}},
url = {http://arxiv.org/abs/1801.06147 http://dx.doi.org/10.2514/6.2018-1659 https://arc.aiaa.org/doi/10.2514/6.2018-1659},
year = {2018}
}
@article{Burden2001,
author = {Burden, Frank R},
doi = {10.1021/ci000459c},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci000459c.pdf:pdf},
pages = {830--835},
title = {{Quantitative Structure - Activity Relationship Studies Using Gaussian Processes}},
year = {2001}
}
@article{Irwin2018a,
abstract = {Copyright {\textcopyright} 2018 American Chemical Society. We present a general method called atom-wise free energy perturbation (AFEP), which extends a conventional molecular dynamics free energy perturbation (FEP) simulation to give the contribution to a free energy change from each atom. AFEP is derived from an expansion of the Zwanzig equation used in the exponential averaging method by defining that the system total energy can be partitioned into contributions from each atom. A partitioning method is assumed and used to group terms in the expansion to correspond to individual atoms. AFEP is applied to six example free energy changes to demonstrate the method. Firstly, the hydration free energies of methane, methanol, methylamine, methanethiol, and caffeine in water. AFEP highlights the atoms in the molecules that interact favorably or unfavorably with water. Finally AFEP is applied to the binding free energy of human immunodeficiency virus type 1 protease to lopinavir, and AFEP reveals the contribution of each atom to the binding free energy, indicating candidate areas of the molecule to improve to produce a more strongly binding inhibitor. FEP gives a single value for the free energy change and is already a very useful method. AFEP gives a free energy change for each "part" of the system being simulated, where part can mean individual atoms, chemical groups, amino acids, or larger partitions depending on what the user is trying to measure. This method should have various applications in molecular dynamics studies of physical, chemical, or biochemical phenomena, specifically in the field of computational drug discovery.},
author = {Irwin, B.W.J. and Huggins, D.J.},
doi = {10.1021/acs.jctc.8b00027},
issn = {15499626},
journal = {Journal of Chemical Theory and Computation},
number = {6},
title = {{Estimating Atomic Contributions to Hydration and Binding Using Free Energy Perturbation}},
volume = {14},
year = {2018}
}
@book{Kolbig1995,
abstract = {7th ed. Previous edition: 2000. The Table of Integrals, Series, and Products is the essential reference for integrals in the English language. Mathematicians, scientists, and engineers, rely on it when identifying and subsequently solving extremely complex problems. Since publication of the first English-language edition in 1965, it has been thoroughly revised and enlarged on a regular basis, with substantial additions and, where necessary, existing entries corrected or revised. The seventh edition includes a fully searchable CD-Rom. - Fully searchable CD that puts information at your fingertips included with text - Most up to date listing of integrals, series and products - Provides accuracy and efficiency in work.},
author = {Kolbig, K. S. and Gradshteyn, I. S. and Ryzhik, I. M. and Jeffrey, Alan and {Scripta Technica}, Inc.},
booktitle = {Mathematics of Computation},
doi = {10.2307/2153347},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/TISPISGIMR.pdf:pdf},
isbn = {9780123736376},
issn = {00255718},
number = {209},
pages = {439},
title = {{Table of Integrals, Series, and Products.}},
volume = {64},
year = {1995}
}
@article{Gomez-Bombarelli2018,
abstract = {We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This model allows us to generate new molecules for efficient exploration and optimization through open-ended spaces of chemical compounds. A deep neural network was trained on hundreds of thousands of existing chemical structures to construct three coupled functions: an encoder, a decoder and a predictor. The encoder converts the discrete representation of a molecule into a real-valued continuous vector, and the decoder converts these continuous vectors back to discrete molecular representations. The predictor estimates chemical properties from the latent continuous vector representation of the molecule. Continuous representations allow us to automatically generate novel chemical structures by performing simple operations in the latent space, such as decoding random vectors, perturbing known chemical structures, or interpolating between molecules. Continuous representations also allow the use of powerful gradient-based optimization to efficiently guide the search for optimized functional compounds. We demonstrate our method in the domain of drug-like molecules and also in the set of molecules with fewer that nine heavy atoms.},
author = {G{\'{o}}mez-Bombarelli, Rafael and Wei, Jennifer N. and Duvenaud, David and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and S{\'{a}}nchez-Lengeling, Benjam{\'{i}}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D. and Adams, Ryan P. and Aspuru-Guzik, Al{\'{a}}n},
doi = {10.1021/acscentsci.7b00572},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acscentsci.7b00572.pdf:pdf},
issn = {2374-7943},
journal = {ACS Central Science},
month = {feb},
number = {2},
pages = {268--276},
title = {{Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules}},
url = {http://pubs.acs.org/doi/10.1021/acscentsci.7b00572},
volume = {4},
year = {2018}
}
@article{Fox1961,
author = {Fox, Charles},
doi = {10.2307/1993339},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/3fd0e89869fbec22ec5055a7ba468c897ce6.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
number = {3},
pages = {395},
title = {{The G and H Functions as Symmetrical Fourier Kernels}},
volume = {98},
year = {1961}
}
@article{Carlson1963,
author = {Carlson, B. C.},
doi = {10.1016/0022-247X(63)90067-2},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/CarlsonR{\_}Lauricella.pdf:pdf},
issn = {10960813},
journal = {Journal of Mathematical Analysis and Applications},
number = {3},
pages = {452--470},
title = {{Lauricella's hypergeometric function FD}},
volume = {7},
year = {1963}
}
@article{Baskin2016,
author = {Baskin, Igor I and Winkler, David and Tetko, Igor V},
doi = {10.1080/17460441.2016.1201262},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Baskin{\_}II-2016-A{\_}renaissance{\_}of{\_}neural{\_}networks{\_}in{\_}drug{\_}discovery.pdf:pdf},
issn = {1746-0441},
journal = {Expert Opinion on Drug Discovery},
keywords = {deep learning,network ensembles,networks,neural,overfitting},
month = {aug},
number = {8},
pages = {785--795},
title = {{A renaissance of neural networks in drug discovery}},
url = {http://www.tandfonline.com/doi/full/10.1080/17460441.2016.1201262},
volume = {11},
year = {2016}
}
@article{Ramsundar2017,
abstract = {Multitask deep learning has emerged as a powerful tool for computational drug discovery. However, despite a number of preliminary studies, multitask deep networks have yet to be widely deployed in the pharmaceutical and biotech industries. This lack of acceptance stems from both software difficulties and lack of understanding of the robustness of multitask deep networks. Our work aims to resolve both of these barriers to adoption. We introduce a high-quality open-source implementation of multitask deep networks as part of the DeepChem open-source platform. Our implementation enables simple python scripts to construct, fit, and evaluate sophisticated deep models. We use our implementation to analyze the performance of multitask deep networks and related deep models on four collections of pharmaceutical data (three of which have not previously been analyzed in the literature). We split these data sets into train/valid/test using time and neighbor splits to test multitask deep learning performance under chal...},
author = {Ramsundar, Bharath and Liu, Bowen and Wu, Zhenqin and Verras, Andreas and Tudor, Matthew and Sheridan, Robert P. and Pande, Vijay},
doi = {10.1021/acs.jcim.7b00146},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.7b00146.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {aug},
number = {8},
pages = {2068--2076},
title = {{Is Multitask Deep Learning Practical for Pharma?}},
url = {http://pubs.acs.org/doi/10.1021/acs.jcim.7b00146},
volume = {57},
year = {2017}
}
@article{Xu2017,
abstract = {Deep neural networks (DNNs) are complex computational models that have found great success in many artificial intelligence applications, such as computer vision1,2 and natural language processing.3,4 In the past four years, DNNs have also generated promising results for quantitative structure–activity relationship (QSAR) tasks.5,6 Previous work showed that DNNs can routinely make better predictions than traditional methods, such as random forests, on a diverse collection of QSAR data sets. It was also found that multitask DNN models—those trained on and predicting multiple QSAR properties simultaneously—outperform DNNs trained separately on the individual data sets in many, but not all, tasks. To date there has been no satisfactory explanation of why the QSAR of one task embedded in a multitask DNN can borrow information from other unrelated QSAR tasks. Thus, using multitask DNNs in a way that consistently provides a predictive advantage becomes a challenge. In this work, we explored why multitask DNNs ma...},
author = {Xu, Yuting and Ma, Junshui and Liaw, Andy and Sheridan, Robert P. and Svetnik, Vladimir},
doi = {10.1021/acs.jcim.7b00087},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.7b00087.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {10},
pages = {2490--2504},
title = {{Demystifying Multitask Deep Neural Networks for Quantitative Structure-Activity Relationships}},
volume = {57},
year = {2017}
}
@article{Muller2015,
abstract = {In this paper we report quantitative structure-activity models linking in vivo Drug-Induced Liver Injury (DILI) of organic molecules with some parameters both measured experimentally in vitro and calculated theoretically from the molecular structure. At the first step, a small database containing information of DILI in humans was created and annotated by experimentally observed information concerning hepatotoxic effects. Thus, for each compound a binary annotation "yes/no" was applied to DILI and seven endpoints causing different liver pathologies in humans: Cholestasis (CH), Oxidative Stress (OS), Mitochondrial injury (MT), Cirrhosis and Steatosis (CS), Hepatitis (HS), Hepatocellular (HC), and Reactive Metabolite (RM). Different machine-learning methods were used to build classification models linking DILI with molecular structure: Support Vector Machines, Artificial Neural Networks and Random Forests. Three types of models were developed: (i) involving molecular descriptors calculated directly from chemical structure, (ii) involving selected endpoints as "biological" descriptors, and (iii) involving both types of descriptors. It has been found that the models based solely on molecular descriptors have much weaker prediction performance than those involving in vivo measured endpoints. Taking into account difficulties in obtaining of in vivo data, at the validation stage we used instead five endpoints (CH, CS, HC, MT and OS) measured in vitro in human hepatocyte cultures. The models involving either some of experimental in vitro endpoints or their combination with theoretically calculated ones correctly predict DILI for 9 out of 10 reference compounds of the external test set. This opens an interesting perspective to use for DILI predictions a combination of theoretically calculated parameters and measured in vitro biological data.},
author = {Muller, Christophe and Pekthong, Dumrongsak and Alexandre, Eliane and Marcou, Gilles and Horvath, Dragos and Richert, Lysiane and Varnek, Alexandre},
doi = {10.2174/1386207318666150305144650},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Muller-et-al.-CCHTS-2015.pdf:pdf},
issn = {13862073},
journal = {Combinatorial Chemistry {\&} High Throughput Screening},
keywords = {biological descriptor,drug-induced liver injury,human hepatocyte cultures,machine-learning methods,molecular},
number = {3},
pages = {315--322},
title = {{Prediction of Drug Induced Liver Injury Using Molecular and Biological Descriptors}},
volume = {18},
year = {2015}
}
@article{Pham2019,
abstract = {Machine learning and deep learning have gained popularity and achieved immense success in Drug discovery in recent decades. Historically, machine learning and deep learning models were trained on either structural data or chemical properties by separated model. In this study, we proposed an architecture training simultaneously both type of data in order to improve the overall performance. Given the molecular structure in the form of SMILES notation and their label, we generated the SMILES-based feature matrix and molecular descriptors. These data was trained on an deep learning model which was also integrated with the Attention mechanism to facilitate training and interpreting. Experiments showed that our model could raise the performance of model. With the maximum MCC 0.56 and AUC 91{\%} by cross-validation on EGFR inhibitors dataset, our architecture was outperforming the referring model. We also successfully integrated Attention mechanism into our model, which helped to interpret the contribution of chemical structures on bioactivity.},
archivePrefix = {arXiv},
arxivId = {1906.05168},
author = {Pham, Huy Ngoc and Le, Trung Hoang},
eprint = {1906.05168},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1906.05168.pdf:pdf},
title = {{Attention-based Multi-Input Deep Learning Architecture for Biological Activity Prediction: An Application in EGFR Inhibitors}},
url = {http://arxiv.org/abs/1906.05168},
year = {2019}
}
@article{Feinberg2018,
author = {Feinberg, Evan N and Sur, Debnil and Wu, Zhenqin and Husic, Brooke E and Mai, Huanghao and Li, Yang and Sun, Saisai and Yang, Jianyi and Ramsundar, Bharath and Pande, Vijay S},
doi = {10.1021/acscentsci.8b00507},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acscentsci.8b00507.pdf:pdf},
issn = {2374-7943},
journal = {ACS Central Science},
month = {nov},
number = {11},
pages = {1520--1530},
publisher = {American Chemical Society},
title = {{PotentialNet for Molecular Property Prediction}},
url = {http://pubs.acs.org/doi/10.1021/acscentsci.8b00507},
volume = {4},
year = {2018}
}
@article{Nguyen2017,
abstract = {Background: Multiple imputation has become very popular as a general-purpose method for handling missing data. The validity of multiple-imputation-based analyses relies on the use of an appropriate model to impute the missing values. Despite the widespread use of multiple imputation, there are few guidelines available for checking imputation models. Analysis: In this paper, we provide an overview of currently available methods for checking imputation models. These include graphical checks and numerical summaries, as well as simulation-based methods such as posterior predictive checking. These model checking techniques are illustrated using an analysis affected by missing data from the Longitudinal Study of Australian Children. Conclusions: As multiple imputation becomes further established as a standard approach for handling missing data, it will become increasingly important that researchers employ appropriate model checking approaches to ensure that reliable results are obtained when using this method.},
author = {Nguyen, Cattram D. and Carlin, John B. and Lee, Katherine J.},
doi = {10.1186/s12982-017-0062-6},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley{\_}Multiple{\_}Imputation/s12982-017-0062-6.pdf:pdf},
issn = {17427622},
journal = {Emerging Themes in Epidemiology},
keywords = {Cross-validation,Diagnostics,Missing data,Model checking,Multiple imputation,Posterior predictive checking},
number = {1},
pages = {1--12},
publisher = {BioMed Central},
title = {{Model checking in multiple imputation: An overview and case study}},
volume = {14},
year = {2017}
}
@article{Pradeep2016,
abstract = {{\textcopyright} 2016 The Author(s).Quantitative structure activity relationships (QSARs) are theoretical models that relate a quantitative measure of chemical structure to a physical property or a biological effect. QSAR predictions can be used for chemical risk assessment for protection of human and environmental health, which makes them interesting to regulators, especially in the absence of experimental data. For compatibility with regulatory use, QSAR models should be transparent, reproducible and optimized to minimize the number of false negatives. In silico QSAR tools are gaining wide acceptance as a faster alternative to otherwise time-consuming clinical and animal testing methods. However, different QSAR tools often make conflicting predictions for a given chemical and may also vary in their predictive performance across different chemical datasets. In a regulatory context, conflicting predictions raise interpretation, validation and adequacy concerns. To address these concerns, ensemble learning techniques in the machine learning paradigm can be used to integrate predictions from multiple tools. By leveraging various underlying QSAR algorithms and training datasets, the resulting consensus prediction should yield better overall predictive ability. We present a novel ensemble QSAR model using Bayesian classification. The model allows for varying a cut-off parameter that allows for a selection in the desirable trade-off between model sensitivity and specificity. The predictive performance of the ensemble model is compared with four in silico tools (Toxtree, Lazar, OECD Toolbox, and Danish QSAR) to predict carcinogenicity for a dataset of air toxins (332 chemicals) and a subset of the gold carcinogenic potency database (480 chemicals). Leave-one-out cross validation results show that the ensemble model achieves the best trade-off between sensitivity and specificity (accuracy: 83.8 {\%} and 80.4 {\%}, and balanced accuracy: 80.6 {\%} and 80.8 {\%}) and highest inter-rater agreement [kappa ($\kappa$): 0.63 and 0.62] for both the datasets. The ROC curves demonstrate the utility of the cut-off feature in the predictive ability of the ensemble model. This feature provides an additional control to the regulators in grading a chemical based on the severity of the toxic endpoint under study.},
author = {Pradeep, Prachi and Povinelli, Richard J. and White, Shannon and Merrill, Stephen J.},
doi = {10.1186/s13321-016-0164-0},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/13321{\_}2016{\_}Article{\_}164.pdf:pdf},
isbn = {1332101601640},
issn = {17582946},
journal = {Journal of Cheminformatics},
keywords = {Computational toxicology,Ensemble models,Hybrid QSAR models,In silico QSAR tools,Risk assessment},
number = {1},
pages = {1--9},
publisher = {Springer International Publishing},
title = {{An ensemble model of QSAR tools for regulatory risk assessment}},
volume = {8},
year = {2016}
}
@article{Irwin2019,
abstract = {{\textcopyright} 2019 American Chemical Society. Hydration sites are locations of interest to water and they can be used to classify the behavior of water around chemical motifs commonly found on the surface of proteins. Inhomogeneous fluid solvation theory (IFST) is a method for calculating hydration free-energy changes from molecular dynamics (MD) trajectories. In this paper, hydration sites are identified from MD simulations of 380 diverse protein structures. The hydration free energies of the hydration sites are calculated using IFST and distributions of these free-energy changes are analyzed. The results show that for some hydration sites near features conventionally regarded as attractive to water, such as hydrogen bond donors, the water molecules are actually relatively weakly bound and are easily displaced. We also construct plots of the spatial density of hydration sites with high, medium, and low hydration free-energy changes which represent weakly and strongly bound hydration sites. It is found that these plots show consistent features around common polar amino acids for all of the proteins studied.},
author = {Irwin, B.W.J. and Vukovic, S. and Payne, M.C. and Huggins, D.J.},
doi = {10.1021/acs.jpcb.9b02490},
issn = {15205207},
journal = {Journal of Physical Chemistry B},
number = {19},
title = {{Large-Scale Study of Hydration Environments through Hydration Sites}},
volume = {123},
year = {2019}
}
@article{Jia2009,
author = {Jia, Zhenya and Davis, Eddie and Muzzio, Fernando J},
doi = {10.1007/s12247-009-9070-6},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Predictive{\_}Modeling{\_}for{\_}Pharmaceutical{\_}Processes{\_}U.pdf:pdf},
keywords = {feeders,kriging,modeling,optimization,powder feeding,response surface},
number = {July 2015},
title = {{Predictive Modeling for Pharmaceutical Processes Using Kriging and Response Predictive Modeling for Pharmaceutical Processes Using Kriging and Response Surface}},
year = {2009}
}
@article{Lecun2015,
author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/nature14539.pdf:pdf},
title = {{Deep learning}},
year = {2015}
}
@article{Dearden2017,
abstract = {Following the publication of the history and development of QSAR, it became apparent that a number of matters had not been covered. This addendum is an attempt to rectify that. A very early approach (ca. 60 B.C.) by Lucretius shows that he understood how molecular size and complexity affect liquid viscosity. Comments by Kant (1724-1804) emphasized the necessity of mathematics in science. A claim that the work of von Bibra and Harless in 1847 pre-dated that of Overton and H.H. Meyer is shown not to be correct. K.H. Meyer and Gottlieb-Billroth published in 1920 what is probably the first QSAR equation. Brown, who with his co-author Fraser is credited with the first definitive recognition in 1868-9 that biological activity is a function of molecular structure, is often cited as Crum Brown; in fact, Crum was his second given name. The QSAR work of the Soviet chemist N.V. Lazarev in the 1940s was far ahead of his time, showing numerous correlations of biological activities and physicochemical properties with molecular descriptors. The subject of inverse QSAR is discussed.},
author = {Dearden, John C.},
doi = {10.4018/IJQSPR.2017070104},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/the-history-and-development-of-quantitative-structure-activity-relationships-(qsars).pdf:pdf},
issn = {2379-7487},
journal = {International Journal of Quantitative Structure-Property Relationships},
keywords = {1816,corwin hansch,crum brown and fraser,descriptors,environmental sciences,introduction,newer approaches,pharmacology,statistics,what is a qsar},
month = {jul},
number = {2},
pages = {36--46},
title = {{The History and Development of Quantitative Structure-Activity Relationships (QSARs)}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/IJQSPR.2017070104},
volume = {2},
year = {2017}
}
@article{Abadi2016,
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Brain, Google and Osdi, Implementation and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/osdi16-abadi.pdf:pdf},
isbn = {9781931971331},
title = {{TensorFlow : A System for Large-Scale Machine Learning This paper is included in the Proceedings of the TensorFlow : A system for large-scale machine learning}},
year = {2016}
}
@inproceedings{Whitehead2019b,
author = {Whitehead, T. M. and Irwin, B. W. J. and Hunt, P. A. and Segall, M. D. and Conduit, G. J.},
booktitle = {ABSTRACTS OF PAPERS OF THE AMERICAN CHEMICAL SOCIETY},
pages = {https://www.optibrium.com/downloads/ACS{\_}Ben{\_}Irwin{\_}},
publisher = {AMER CHEMICAL SOC},
title = {{Imputing compound activities based on sparse and noisy data}},
url = {https://www.optibrium.com/downloads/ACS{\_}Ben{\_}Irwin{\_}Practical{\_}Applications{\_}Final.pdf},
year = {2019}
}
@article{Verpoort2018,
author = {Verpoort, P.C. and MacDonald, P. and Conduit, G.J.},
doi = {10.1016/j.commatsci.2018.02.002},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/VerpoortMacDonaldConduit18(1).pdf:pdf},
issn = {09270256},
journal = {Computational Materials Science},
keywords = {Alloys,Materials data,Neural network,Polymers},
month = {may},
pages = {176--185},
title = {{Materials data validation and imputation with an artificial neural network}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0927025618300855},
volume = {147},
year = {2018}
}
@article{Martinez2019,
abstract = {The selection of the most relevant molecular descriptors to describe a target variable in the context of QSAR (Quantitative Structure-Activity Relationship) modelling is a challenging combinatorial optimization problem. In this paper, a novel software tool for addressing this task in the context of regression and classification modelling is presented. The methodology that implements the tool is organized into two phases. The first phase uses a multiobjective evolutionary technique to perform the selection of subsets of descriptors. The second phase performs an external validation of the chosen descriptors subsets in order to improve reliability. The tool functionalities have been illustrated through a case study for the estimation of the ready biodegradation property as an example of classification QSAR modelling. The results obtained show the usefulness and potential of this novel software tool that aims to reduce the time and costs of development in the drug discovery process.},
author = {Martinez, Maria Jimena and Razuc, Marina and Ponzoni, Ignacio},
doi = {10.1155/2019/2905203},
file = {:C$\backslash$:/Users/ben/Downloads/2905203.pdf:pdf},
issn = {23146141},
journal = {BioMed Research International},
title = {{MoDeSuS: A machine learning tool for selection of molecular descriptors in qsar studies applied to molecular informatics}},
volume = {2019},
year = {2019}
}
@article{Tetko2001,
author = {Tetko, Igor V and Tanchuk, Vsevolod Yu and Villa, Alessandro E P},
doi = {10.1021/ci010368v},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci010368v.pdf:pdf},
pages = {1407--1421},
title = {{Prediction of n -Octanol / Water Partition Coefficients from PHYSPROP Database Using Artificial Neural Networks and E-State Indices}},
year = {2001}
}
@article{MacRobert1962,
author = {MacRobert, T. M.},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/MacRobertE.pdf:pdf},
journal = {Math Annalen.},
title = {{Barnes Integrals as a Sum of E-Functions}},
year = {1962}
}
@article{Shahlaei2013,
author = {Shahlaei, Mohsen and Fassihi, Afshin},
doi = {10.1007/s00044-012-0430-2},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Shahlaei-Fassihi2013{\_}Article{\_}QSARAnalysisOfSome1-33-dipheny.pdf:pdf},
isbn = {0004401204302},
keywords = {inhibitors {\'{a}} anti-hiv agents,least square support,multivariate linear regression {\'{a}},quantitative structure activity relationship,vector machine {\'{a}} ccr5,{\'{a}}},
pages = {4384--4400},
title = {{CHEMISTRY QSAR analysis of some 1- ( 3 , 3-diphenylpropyl ) -piperidinyl amides and ureas as CCR5 inhibitors using genetic algorithm-least square support vector machine}},
year = {2013}
}
@article{Inayat-Hussain1987,
abstract = {For pt. I, see ibid., vol.20, p.4109 (1987). Further examples of the use of Feynman integrals enable the derivation of new properties of hypergeometric series including new analytic continuation formulae for a generalised hypergeometric series and for a Kampe de Feriet function. This motivates the derivation of two new summation formulae for a generalised hypergeometric series and furthermore leads to a natural generalisation of the H function. While the latter, as is well known, contains as particular cases most of the special functions of applied mathematics, it does not contain some of importance, for instance the Riemann zeta function nor indeed any polylogarithm. Our generalisation of the H function does contain the polylogarithm; it also contains the exact partition function of the Gaussian model from statistical mechanics. Another new result is the simple summation formula 3F 2(1,1,3/2;2,2; x)=-(-)-1 ln((1+(1-x)12/)/2).},
author = {Inayat-Hussain, A. A.},
doi = {10.1088/0305-4470/20/13/020},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/A{\_}A{\_}Inayat-Hussain{\_}1987{\_}J.{\_}Phys.{\_}A{\_}{\_}Math.{\_}Gen.{\_}20{\_}020.pdf:pdf},
issn = {03054470},
journal = {Journal of Physics A: General Physics},
number = {13},
pages = {4119--4128},
title = {{New properties of hypergeometric series derivable from Feynman integrals II. A generalisation of the H function}},
volume = {20},
year = {1987}
}
@article{Ambikasaran2014,
abstract = {A number of problems in probability and statistics can be addressed using the multivariate normal (Gaussian) distribution. In the one-dimensional case, computing the probability for a given mean and variance simply requires the evaluation of the corresponding Gaussian density. In the {\$}n{\$}-dimensional setting, however, it requires the inversion of an {\$}n \backslashtimes n{\$} covariance matrix, {\$}C{\$}, as well as the evaluation of its determinant, {\$}\backslashdet(C){\$}. In many cases, such as regression using Gaussian processes, the covariance matrix is of the form {\$}C = \backslashsigma{\^{}}2 I + K{\$}, where {\$}K{\$} is computed using a specified covariance kernel which depends on the data and additional parameters (hyperparameters). The matrix {\$}C{\$} is typically dense, causing standard direct methods for inversion and determinant evaluation to require {\$}\backslashmathcal O(n{\^{}}3){\$} work. This cost is prohibitive for large-scale modeling. Here, we show that for the most commonly used covariance functions, the matrix {\$}C{\$} can be hierarchically factored into a product of block low-rank updates of the identity matrix, yielding an {\$}\backslashmathcal O (n\backslashlog{\^{}}2 n) {\$} algorithm for inversion. More importantly, we show that this factorization enables the evaluation of the determinant {\$}\backslashdet(C){\$}, permitting the direct calculation of probabilities in high dimensions under fairly broad assumptions on the kernel defining {\$}K{\$}. Our fast algorithm brings many problems in marginalization and the adaptation of hyperparameters within practical reach using a single CPU core. The combination of nearly optimal scaling in terms of problem size with high-performance computing resources will permit the modeling of previously intractable problems. We illustrate the performance of the scheme on standard covariance kernels.},
archivePrefix = {arXiv},
arxivId = {1403.6015},
author = {Ambikasaran, Sivaram and Foreman-Mackey, Daniel and Greengard, Leslie and Hogg, David W and O'Neil, Michael},
eprint = {1403.6015},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1403.6015.pdf:pdf},
month = {mar},
pages = {1--14},
title = {{Fast Direct Methods for Gaussian Processes}},
url = {http://arxiv.org/abs/1403.6015},
year = {2014}
}
@incollection{Gonzalez2015b,
author = {Gonzalez, Ivan and Kohl, Karen T and Moll, Victor H},
doi = {10.1201/b19419-15},
file = {:C$\backslash$:/Users/ben/Downloads/ram-125.pdf:pdf},
month = {oct},
number = {January 2014},
pages = {195--214},
title = {{Evaluation of entries in Gradshteyn and Ryzhik employing the method of brackets}},
url = {http://www.crcnetbase.com/doi/10.1201/b19419-15},
year = {2015}
}
@article{Schmidhuber2015,
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S0893608014002135-main.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
month = {jan},
pages = {85--117},
publisher = {Elsevier Ltd},
title = {{Deep learning in neural networks: An overview}},
url = {http://dx.doi.org/10.1016/j.neunet.2014.09.003 https://linkinghub.elsevier.com/retrieve/pii/S0893608014002135},
volume = {61},
year = {2015}
}
@article{Svensson2018,
abstract = {{\textcopyright} 2018 American Chemical Society. Making predictions with an associated confidence is highly desirable as it facilitates decision making and resource prioritization. Conformal regression is a machine learning framework that allows the user to define the required confidence and delivers predictions that are guaranteed to be correct to the selected extent. In this study, we apply conformal regression to model molecular properties and bioactivity values and investigate different ways to scale the resultant prediction intervals to create as efficient (i.e., narrow) regressors as possible. Different algorithms to estimate the prediction uncertainty were used to normalize the prediction ranges, and the different approaches were evaluated on 29 publicly available data sets. Our results show that the most efficient conformal regressors are obtained when using the natural exponential of the ensemble standard deviation from the underlying random forest to scale the prediction intervals, but other approaches were almost as efficient. This approach afforded an average prediction range of 1.65 pIC50 units at the 80{\%} confidence level when applied to bioactivity modeling. The choice of nonconformity function has a pronounced impact on the average prediction range with a difference of close to one log unit in bioactivity between the tightest and widest prediction range. Overall, conformal regression is a robust approach to generate bioactivity predictions with associated confidence.},
author = {Svensson, Fredrik and Aniceto, Natalia and Norinder, Ulf and Cortes-Ciriano, Isidro and Spjuth, Ola and Carlsson, Lars and Bender, Andreas},
doi = {10.1021/acs.jcim.8b00054},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.8b00054.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {5},
pages = {1132--1140},
publisher = {American Chemical Society},
title = {{Conformal Regression for Quantitative Structure-Activity Relationship Modeling - Quantifying Prediction Uncertainty}},
volume = {58},
year = {2018}
}
@incollection{Paszke2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d$\backslash$textquotesingle Alch{\'{e}}-Buc, F and Fox, E and Garnett, R},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}
@article{Bengio,
author = {Bengio, Yoshua},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/TR1312.pdf:pdf},
title = {{TR1312.pdfLearning Deep Architectures for AI}}
}
@article{Jones2001,
author = {Jones, Donald R},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Jones2001{\_}Article{\_}ATaxonomyOfGlobalOptimizationM.pdf:pdf},
keywords = {global optimization,kriging,response surface,splines},
pages = {345--383},
title = {{A Taxonomy of Global Optimization Methods Based on Response Surfaces}},
year = {2001}
}
@article{Yang2019,
abstract = {Advancements in neural machinery have led to a wide range of algorithmic solutions for molecular property prediction. Two classes of models in particular have yielded promising results: neural networks applied to computed molecular fingerprints or expert-crafted descriptors and graph convolutional neural networks that construct a learned molecular representation by operating on the graph structure of the molecule. However, recent literature has yet to clearly determine which of these two methods is superior when generalizing to new chemical space. Furthermore, prior research has rarely examined these new models in industry research settings in comparison to existing employed models. In this paper, we benchmark models extensively on 19 public and 16 proprietary industrial data sets spanning a wide variety of chemical end points. In addition, we introduce a graph convolutional model that consistently matches or outperforms models using fixed molecular descriptors as well as previous graph neural architectures on both public and proprietary data sets. Our empirical findings indicate that while approaches based on these representations have yet to reach the level of experimental reproducibility, our proposed model nevertheless offers significant improvements over models currently used in industrial workflows.},
archivePrefix = {arXiv},
arxivId = {1904.01561},
author = {Yang, Kevin and Swanson, Kyle and Jin, Wengong and Coley, Connor and Eiden, Philipp and Gao, Hua and Guzman-Perez, Angel and Hopper, Timothy and Kelley, Brian and Mathea, Miriam and Palmer, Andrew and Settels, Volker and Jaakkola, Tommi and Jensen, Klavs and Barzilay, Regina},
doi = {10.1021/acs.jcim.9b00237},
eprint = {1904.01561},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.9b00237.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {8},
pages = {3370--3388},
publisher = {American Chemical Society},
title = {{Analyzing Learned Molecular Representations for Property Prediction}},
volume = {59},
year = {2019}
}
@article{Liu2018,
annote = {doi: 10.1080/17460441.2018.1403419},
author = {Liu, Xuewei and Shi, Danfeng and Zhou, Shuangyan and Liu, Hongli and Liu, Huanxiang and Yao, Xiaojun},
doi = {10.1080/17460441.2018.1403419},
issn = {1746-0441},
journal = {Expert Opinion on Drug Discovery},
month = {jan},
number = {1},
pages = {23--37},
publisher = {Taylor {\&} Francis},
title = {{Molecular dynamics simulations and novel drug discovery}},
url = {https://doi.org/10.1080/17460441.2018.1403419},
volume = {13},
year = {2018}
}
@article{Christmann-Franck2016,
abstract = {Drug discovery programs frequently target members of the human kinome and try to identify small molecule protein kinase inhibitors, primarily for cancer treatment, additional indications being increasingly investigated. One of the challenges is controlling the inhibitors degree of selectivity, assessed by in vitro profiling against panels of protein kinases. We manually extracted, compiled, and standardized such profiles published in the literature: we collected 356 908 data points corresponding to 482 protein kinases, 2106 inhibitors, and 661 patents. We then analyzed this data set in terms of kinome coverage, results reproducibility, popularity, and degree of selectivity of both kinases and inhibitors. We used the data set to create robust proteochemometric models capable of predicting kinase activity (the ligand-target space was modeled with an externally validated RMSE of 0.41 ± 0.02 log units and R02 0.74 ± 0.03), in order to account for missing or unreliable measurements. The influence on the prediction quality of parameters such as number of measurements, Murcko scaffold frequency or inhibitor type was assessed. Interpretation of the models enabled to highlight inhibitors and kinases properties correlated with higher affinities, and an analysis in the context of kinases crystal structures was performed. Overall, the models quality allows the accurate prediction of kinase-inhibitor activities and their structural interpretation, thus paving the way for the rational design of compounds with a targeted selectivity profile.},
author = {Christmann-Franck, Serge and van Westen, Gerard J. P. and Papadatos, George and {Beltran Escudie}, Fanny and Roberts, Alexander and Overington, John P. and Domine, Daniel},
doi = {10.1021/acs.jcim.6b00122},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.6b00122.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {sep},
number = {9},
pages = {1654--1675},
title = {{Unprecedently Large-Scale Kinase Inhibitor Set Enabling the Accurate Prediction of Compound–Kinase Activities: A Way toward Selective Promiscuity by Design?}},
url = {https://pubs.acs.org/doi/10.1021/acs.jcim.6b00122},
volume = {56},
year = {2016}
}
@book{Erdelyi1954,
author = {Erd{\'{e}}lyi, A},
file = {:C$\backslash$:/Users/ben/Desktop/Bateman.txt:txt},
title = {{Table of Integral Transforms, Vol. I}},
volume = {1},
year = {1954}
}
@article{Smieja2018a,
abstract = {We propose a general, theoretically justified mechanism for processing missing data by neural networks. Our idea is to replace typical neuron's response in the first hidden layer by its expected value. This approach can be applied for various types of networks at minimal cost in their modification. Moreover, in contrast to recent approaches, it does not require complete data for training. Experimental results performed on different types of architectures show that our method gives better results than typical imputation strategies and other methods dedicated for incomplete data.},
archivePrefix = {arXiv},
arxivId = {1805.07405},
author = {Smieja, Marek and Struski, {\L}ukasz and Tabor, Jacek and Zieli{\'{n}}ski, Bartosz and Spurek, Przemys{\l}aw},
eprint = {1805.07405},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1805.07405.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {may},
number = {Section 4},
pages = {2719--2729},
title = {{Processing of missing data by neural networks}},
url = {http://arxiv.org/abs/1805.07405},
volume = {2018-Decem},
year = {2018}
}
@article{Thrun1997,
author = {Thrun, Sebastian},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Caruana1997{\_}Article{\_}MultitaskLearning.pdf:pdf},
keywords = {backpropagation,generalization,inductive transfer,k-nearest neighbor,kernel,multitask learning,parallel transfer,regression,supervised learning},
pages = {41--75},
title = {{Multitask Learning *}},
volume = {75},
year = {1997}
}
@article{Society2019,
author = {Society, Royal Statistical},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/2984809.pdf:pdf},
keywords = {analysis of variance,choice of variables,crossvalidation,doublecross,modelmix,multiple regression,prediction,prescription,univariate estimation},
number = {2},
pages = {111--147},
title = {{Cross-Validatory Choice and Assessment of Statistical Predictions Author ( s ): M . Stone Source : Journal of the Royal Statistical Society . Series B ( Methodological ), Vol . 36 , No . 2 Published by : Wiley for the Royal Statistical Society Stable URL }},
volume = {36},
year = {2019}
}
@article{Cherkasov2014,
author = {Cherkasov, Artem and Muratov, Eugene N and Fourches, Denis and Varnek, Alexandre and Baskin, Igor I. and Cronin, Mark and Dearden, John and Gramatica, Paola and Martin, Yvonne C and Todeschini, Roberto and Consonni, Viviana and Kuz'min, Victor E. and Cramer, Richard and Benigni, Romualdo and Yang, Chihae and Rathman, James and Terfloth, Lothar and Gasteiger, Johann and Richard, Ann and Tropsha, Alexander},
doi = {10.1021/jm4004285},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/nihms553656.pdf:pdf},
issn = {0022-2623},
journal = {Journal of Medicinal Chemistry},
month = {jun},
number = {12},
pages = {4977--5010},
title = {{QSAR Modeling: Where Have You Been? Where Are You Going To?}},
url = {http://pubs.acs.org/doi/10.1021/jm4004285},
volume = {57},
year = {2014}
}
@article{Wang2012,
author = {Wang, Lingle and Berne, B J and Friesner, Richard A},
doi = {10.1073/pnas.1114017109},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1937.full.pdf:pdf},
number = {6},
title = {{On achieving high accuracy and reliability in the calculation of relative protein – ligand binding affinities}},
volume = {109},
year = {2012}
}
@article{Amdeberhan2012,
abstract = {S. Ramanujan introduced a technique, known as Ramanujan's Master Theorem, which provides an explicit expression for the Mellin transform of a function in terms of the analytic continuation of its Taylor coefficients. The history and proof of this result are reviewed, and a variety of applications is presented. Finally, a multi-dimensional extension of Ramanujan's Master Theorem is discussed.},
author = {Amdeberhan, Tewodros and Espinosa, Olivier and Gonzalez, Ivan and Harrison, Marshall and Moll, Victor H and Straub, Armin},
doi = {10.1007/s11139-011-9333-y},
issn = {1382-4090},
journal = {The Ramanujan Journal},
month = {dec},
number = {1-3},
pages = {103--120},
title = {{Ramanujan's Master Theorem}},
url = {https://doi.org/10.1007/s11139-011-9333-y http://link.springer.com/10.1007/s11139-011-9333-y},
volume = {29},
year = {2012}
}
@article{Santak2019,
author = {Santak, Pavao and Conduit, Gareth},
doi = {10.1016/j.fluid.2019.112259},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S0378381219303188-main.pdf:pdf},
issn = {0378-3812},
journal = {Fluid Phase Equilibria},
keywords = {alkane,flash point,fragmented data,lubricant,neural network},
pages = {112259},
publisher = {Elsevier B.V.},
title = {{Predicting physical properties of alkanes with neural networks}},
url = {https://doi.org/10.1016/j.fluid.2019.112259},
year = {2019}
}
@article{Geoga2018,
abstract = {We present a kernel-independent method that applies hierarchical matrices to the problem of maximum likelihood estimation for Gaussian processes. The proposed approximation provides natural and scalable stochastic estimators for its gradient and Hessian, as well as the expected Fisher information matrix, that are computable in quasilinear {\$}O(n \backslashlog{\^{}}2 n){\$} complexity for a large range of models. To accomplish this, we (i) choose a specific hierarchical approximation for covariance matrices that enables the computation of their exact derivatives and (ii) use a stabilized form of the Hutchinson stochastic trace estimator. Since both the observed and expected information matrices can be computed in quasilinear complexity, covariance matrices for MLEs can also be estimated efficiently. After discussing the associated mathematics, we demonstrate the scalability of the method, discuss details of its implementation, and validate that the resulting MLEs and confidence intervals based on the inverse Fisher information matrix faithfully approach those obtained by the exact likelihood.},
archivePrefix = {arXiv},
arxivId = {1808.03215},
author = {Geoga, Christopher J and Anitescu, Mihai and Stein, Michael L},
eprint = {1808.03215},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1808.03215.pdf:pdf},
keywords = {algorithms,anl,ascr,cgeoga,computing research,corresponding author,department of energy,gov,numerical linear algebra,office of advanced scientific,office of science,s,spatial analysis,statistical computing,the u,this material was based,under contract de-ac02-06ch11347,upon work supported by,we},
month = {aug},
pages = {1--22},
title = {{Scalable Gaussian Process Computations Using Hierarchical Matrices}},
url = {http://arxiv.org/abs/1808.03215},
year = {2018}
}
@incollection{Buhmann2003,
abstract = {In the present age, when computers are applied almost anywhere in science, engineering and, indeed, all around us in day-to-day life, it becomes more and more important to implement mathematical functions for efficient evaluation in computer programs. It is usually necessary for this purpose to use all kinds of ‘approximations' of functions rather than their exact mathematical form. There are various reasons why this is so. A simple one is that in many instances it is not possible to implement the functions exactly, because, for instance, they are only represented by an infinite expansion. Furthermore, the function we want to use may not be completely known to us, or may be too expensive or demanding of computer time and memory to compute in advance, which is another typical, important reason why approximations are required. This is true even in the face of ever increasing speed and computer memory availability, given that additional memory and speed will always increase the demand of the users and the size of the problems which are to be solved. Finally, the data that define the function may have to be computed interactively or by a step-by-step approach which again makes it suitable to compute approximations. With those we can then pursue further computations, for instance, or further evaluations that are required by the user, or display data or functions on a screen.},
address = {Cambridge},
booktitle = {Radial Basis Functions: Theory and Implementations},
doi = {DOI: 10.1017/CBO9780511543241.002},
editor = {Buhmann, Martin D},
isbn = {9780521633383},
pages = {1--10},
publisher = {Cambridge University Press},
series = {Cambridge Monographs on Applied and Computational Mathematics},
title = {{Introduction}},
url = {https://www.cambridge.org/core/books/radial-basis-functions/introduction/D1FEB079AD7F74D6D8B55D32F3530281},
year = {2003}
}
@article{Ghasemi2018,
author = {Ghasemi, Fahimeh and Mehridehnavi, Alireza and Fassihi, Afshin and P{\'{e}}rez-S{\'{a}}nchez, Horacio},
doi = {10.1016/j.asoc.2017.09.040},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/J71.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
month = {jan},
number = {October},
pages = {251--258},
publisher = {Elsevier B.V.},
title = {{Deep neural network in QSAR studies using deep belief network}},
url = {http://dx.doi.org/10.1016/j.asoc.2017.09.040 https://linkinghub.elsevier.com/retrieve/pii/S1568494617305793},
volume = {62},
year = {2018}
}
@article{Mclachlan2008,
author = {Mclachlan, Geoffrey and Krishnan, Thriyambakam},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Wiley{\_}The EM Algorithm and Extensions, 2nd Edition{\_}978-0-471-20170-0.pdf:pdf},
isbn = {9780470191606},
title = {{The EM Algorithm and Extensions , 2nd Edition}},
year = {2008}
}
@article{Li2017,
abstract = {⎯The aqueous solubility of a drug is a significant factor for its bioavailability. Since many drugs on the market are the oral drugs, their absorption and metabolism in organisms are closely related to its aqueous solubility. As one of the most important properties of drug, the molecule aqueous solubility has received increasing attentions in drug discovery field. The methods of shallow machine learning have been applied to the field of pharmacy, with some success. In this paper, we established a multilayer deep belief network based on semi-supervised learning model to predict the aqueous solu-bility of compounds. This method can be used for recognizing whether compounds are soluble or not. Firstly, we discussed the influence of feature dimension to predict accuracy. Secondly, we analyzed the parameters of model in predicting aqueous solubility of drugs and contrasted the shallow machine learning with the similar deep architecture. The results showed that the model we proposed can predict aqueous solubility accurately, the accuracy of DBN reached 85.9{\%}. The stable performance on the evaluation metrics confirms the practicability of our model. Moreover, the DBN model could be applied to reduce the cost and time of drug discovery by predicting aqueous solubility of drugs.},
author = {Li, Hong and Yu, Long and Tian, Shengwei and Li, Li and Wang, Mei and Lu, Xueyuan},
doi = {10.3103/s0146411617020043},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Li2017{\_}Article{\_}DeepLearningInPharmacyThePredi.pdf:pdf},
isbn = {0146411617},
issn = {0146-4116},
journal = {Automatic Control and Computer Sciences},
keywords = {10,3103,aqueous solubility,deep belief network,deep learning,doi,s0146411617020043,semi-supervised machine learning},
number = {2},
pages = {97--107},
title = {{Deep learning in pharmacy: The prediction of aqueous solubility based on deep belief network}},
volume = {51},
year = {2017}
}
@article{Schurer2013,
abstract = {Large corpora of kinase small molecule inhibitor data are accessible to public sector research from thousands of journal article and patent publications. These data have been generated employing a wide variety of assay methodologies and experimental procedures by numerous laboratories. Here we ask the question how applicable these heterogeneous data sets are to predict kinase activities and which characteristics of the data sets contribute to their utility. We accessed almost 500 000 molecules from the Kinase Knowledge Base (KKB) and after rigorous aggregation and standardization generated over 180 distinct data sets covering all major groups of the human kinome. To assess the value of the data sets, we generated hundreds of classification and regression models. Their rigorous cross-validation and characterization demonstrated highly predictive classification and quantitative models for the majority of kinase targets if a minimum required number of active compounds or structure-activity data points were available. We then applied the best classifiers to compounds most recently profiled in the NIH Library of Integrated Network-based Cellular Signatures (LINCS) program and found good agreement of profiling results with predicted activities. Our results indicate that, although heterogeneous in nature, the publically accessible data sets are exceedingly valuable and well suited to develop highly accurate predictors for practical Kinome-wide virtual screening applications and to complement experimental kinase profiling. {\textcopyright} 2012 American Chemical Society.},
author = {Sch{\"{u}}rer, Stephan C. and Muskal, Steven M.},
doi = {10.1021/ci300403k},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci300403k.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {1},
pages = {27--38},
title = {{Kinome-wide activity modeling from diverse public high-quality data sets}},
volume = {53},
year = {2013}
}
@article{Wang2015,
abstract = {PURPOSE: Experimental Blood-Brain Barrier (BBB) permeability models for drug molecules are expensive and time-consuming. As alternative methods, several traditional Quantitative Structure-Activity Relationship (QSAR) models have been developed previously. In this study, we aimed to improve the predictivity of traditional QSAR BBB permeability models by employing relevant public bio-assay data in the modeling process.$\backslash$n$\backslash$nMETHODS: We compiled a BBB permeability database consisting of 439 unique compounds from various resources. The database was split into a modeling set of 341 compounds and a validation set of 98 compounds. Consensus QSAR modeling workflow was employed on the modeling set to develop various QSAR models. A five-fold cross-validation approach was used to validate the developed models, and the resulting models were used to predict the external validation set compounds. Furthermore, we used previously published membrane transporter models to generate relevant transporter profiles for target compounds. The transporter profiles were used as additional biological descriptors to develop hybrid QSAR BBB models.$\backslash$n$\backslash$nRESULTS: The consensus QSAR models have R(2) = 0.638 for five-fold cross-validation and R(2) = 0.504 for external validation. The consensus model developed by pooling chemical and transporter descriptors showed better predictivity (R(2) = 0.646 for five-fold cross-validation and R(2) = 0.526 for external validation). Moreover, several external bio-assays that correlate with BBB permeability were identified using our automatic profiling tool.$\backslash$n$\backslash$nCONCLUSIONS: The BBB permeability models developed in this study can be useful for early evaluation of new compounds (e.g., new drug candidates). The combination of chemical and biological descriptors shows a promising direction to improve the current traditional QSAR models.},
author = {Wang, Wenyi and Kim, Marlene T. and Sedykh, Alexander and Zhu, Hao},
doi = {10.1007/s11095-015-1687-1},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/nihms680309.pdf:pdf},
issn = {1573904X},
journal = {Pharmaceutical Research},
keywords = {biological descriptors,blood-brain barrier,hybrid model,permeability},
number = {9},
pages = {3055--3065},
title = {{Developing Enhanced Blood-Brain Barrier Permeability Models: Integrating External Bio-Assay Data in QSAR Modeling}},
volume = {32},
year = {2015}
}
@article{Feinberg2019,
abstract = {The Absorption, Distribution, Metabolism, Elimination, and Toxicity (ADMET) properties of drug candidates are estimated to account for up to 50{\%} of all clinical trial failures. Predicting ADMET properties has therefore been of great interest to the cheminformatics and medicinal chemistry communities in recent decades. Traditional cheminformatics approaches, whether the learner is a random forest or a deep neural network, leverage fixed fingerprint feature representations of molecules. In contrast, in this paper, we learn the features most relevant to each chemical task at hand by representing each molecule explicitly as a graph, where each node is an atom and each edge is a bond. By applying graph convolutions to this explicit molecular representation, we achieve, to our knowledge, unprecedented accuracy in prediction of ADMET properties. By challenging our methodology with rigorous cross-validation procedures and prospective analyses, we show that deep featurization better enables molecular predictors to not only interpolate but also extrapolate to new regions of chemical space.},
archivePrefix = {arXiv},
arxivId = {1903.11789},
author = {Feinberg, Evan N. and Sheridan, Robert and Joshi, Elizabeth and Pande, Vijay S. and Cheng, Alan C.},
eprint = {1903.11789},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1903.11789.pdf:pdf},
title = {{Step Change Improvement in ADMET Prediction with PotentialNet Deep Featurization}},
url = {http://arxiv.org/abs/1903.11789},
year = {2019}
}
@article{Wang2017,
abstract = {This paper is a review of the evolutionary history of deep learning models. It covers from the genesis of neural networks when associationism modeling of the brain is studied, to the models that dominate the last decade of research in deep learning like convolutional neural networks, deep belief networks, and recurrent neural networks. In addition to a review of these models, this paper primarily focuses on the precedents of the models above, examining how the initial ideas are assembled to construct the early models and how these preliminary models are developed into their current forms. Many of these evolutionary paths last more than half a century and have a diversity of directions. For example, CNN is built on prior knowledge of biological vision system; DBN is evolved from a trade-off of modeling power and computation complexity of graphical models and many nowadays models are neural counterparts of ancient linear models. This paper reviews these evolutionary paths and offers a concise thought flow of how these models are developed, and aims to provide a thorough background for deep learning. More importantly, along with the path, this paper summarizes the gist behind these milestones and proposes many directions to guide the future research of deep learning.},
archivePrefix = {arXiv},
arxivId = {1702.07800},
author = {Wang, Haohan and Raj, Bhiksha},
eprint = {1702.07800},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/DeepLearning Review.pdf:pdf},
month = {feb},
pages = {1--72},
title = {{On the Origin of Deep Learning}},
url = {http://arxiv.org/abs/1702.07800},
year = {2017}
}
@article{Xu2015,
abstract = {Drug-induced liver injury (DILI) has been the single most frequent cause of safety-related drug marketing withdrawals for the past 50 years. Recently, deep learning (DL) has been successfully applied in many fields due to its exceptional and automatic learning ability. In this study, DILI prediction models were developed using DL architectures, and the best model trained on 475 drugs predicted an external validation set of 198 drugs with an accuracy of 86.9{\%}, sensitivity of 82.5{\%}, specificity of 92.9{\%}, and area under the curve of 0.955, which is better than the performance of previously described DILI prediction models. Furthermore, with deep analysis, we also identified important molecular features that are related to DILI. Such DL models could improve the prediction of DILI risk in humans. The DL DILI prediction models are freely available at http://www.repharma.cn/DILIserver/DILI{\_}home.php.$\backslash$nDrug-induced liver injury (DILI) has been the single most frequent cause of safety-related drug marketing withdrawals for the past 50 years. Recently, deep learning (DL) has been successfully applied in many fields due to its exceptional and automatic learning ability. In this study, DILI prediction models were developed using DL architectures, and the best model trained on 475 drugs predicted an external validation set of 198 drugs with an accuracy of 86.9{\%}, sensitivity of 82.5{\%}, specificity of 92.9{\%}, and area under the curve of 0.955, which is better than the performance of previously described DILI prediction models. Furthermore, with deep analysis, we also identified important molecular features that are related to DILI. Such DL models could improve the prediction of DILI risk in humans. The DL DILI prediction models are freely available at http://www.repharma.cn/DILIserver/DILI{\_}home.php.},
author = {Xu, Youjun and Dai, Ziwei and Chen, Fangjin and Gao, Shuaishi and Pei, Jianfeng and Lai, Luhua},
doi = {10.1021/acs.jcim.5b00238},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.5b00238.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {10},
pages = {2085--2093},
title = {{Deep Learning for Drug-Induced Liver Injury}},
volume = {55},
year = {2015}
}
@article{Irwin2017,
abstract = {{\textcopyright} 2017 Author(s). Evaluating solvation entropies directly and combining with direct energy calculations is one way of calculating free energies of solvation and is used by Inhomogeneous Fluid Solvation Theory (IFST). The configurational entropy of a fluid is a function of the interatomic correlations and can thus be expressed in terms of correlation functions. The entropies in this work are directly calculated from a truncated series of integrals over these correlation functions. Many studies truncate all terms higher than the solvent-solute correlations. This study includes an additional solvent-solvent correlation term and assesses the associated free energy when IFST is applied to a fixed Lennard-Jones particle solvated in neon. The strength of the central potential is varied to imitate larger solutes. Average free energy estimates with both levels of IFST are able to reproduce the estimate made using the Free energy Perturbation (FEP) to within 0.16 kcal/mol. We find that the signal from the solvent-solvent correlations is very weak. Our conclusion is that for monatomic fluids simulated by pairwise classical potentials the correction term is relatively small in magnitude. This study shows it is possible to reproduce the free energy from a path based method like FEP, by only considering the endpoints of the path. This method can be directly applied to more complex solutes which break the spherical symmetry of this study.},
author = {Irwin, B.W.J. and Huggins, D.J.},
doi = {10.1063/1.4983654},
issn = {00219606},
journal = {Journal of Chemical Physics},
number = {19},
title = {{On the accuracy of one- and two-particle solvation entropies}},
volume = {146},
year = {2017}
}
@misc{,
keywords = {Stardrop},
mendeley-tags = {Stardrop},
publisher = {(accessed 16/12/2019)},
title = {{StarDrop™}},
url = {https://www.optibrium.com/stardrop/}
}
@article{Martin2017,
abstract = {{\textcopyright} 2017 American Chemical Society. While conventional random forest regression (RFR) virtual screening models appear to have excellent accuracy on random held-out test sets, they prove lacking in actual practice. Analysis of 18 historical virtual screens showed that random test sets are far more similar to their training sets than are the compounds project teams actually order. A new, cluster-based "realistic" training/test set split, which mirrors the chemical novelty of real-life virtual screens, recapitulates the poor predictive power of RFR models in real projects. The original Profile-QSAR (pQSAR) method greatly broadened the domain of applicability over conventional models by using as independent variables a profile of activity predictions from all historical assays in a large protein family. However, the accuracy still fell short of experiment on realistic test sets. The improved "pQSAR 2.0" method replaces probabilities of activity from na{\"{i}}ve Bayes categorical models at several thresholds with predicted IC 50 s from RFR models. Unexpectedly, the high accuracy also requires removing the RFR model for the actual assay of interest from the independent variable profile. With these improvements, pQSAR 2.0 activity predictions are now statistically comparable to medium-throughput four-concentration IC 50  measurements even on the realistic test set. Beyond the yes/no activity predictions from a typical high-throughput screen (HTS) or conventional virtual screen, these semiquantitative IC 50  predictions allow for predicted potency, ligand efficiency, lipophilic efficiency, and selectivity against antitargets, greatly facilitating hitlist triaging and enabling virtual screening panels such as toxicity panels and overall promiscuity predictions.},
author = {Martin, Eric J. and Polyakov, Valery R. and Tian, Li and Perez, Rolando C.},
doi = {10.1021/acs.jcim.7b00166},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.7b00166.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {8},
pages = {2077--2088},
title = {{Profile-QSAR 2.0: Kinase Virtual Screening Accuracy Comparable to Four-Concentration IC50s for Realistically Novel Compounds}},
volume = {57},
year = {2017}
}
@article{Obrezanova2010,
abstract = {In this article, we extend the application of the Gaussian processes technique to classification quantitative structure-activity relationship modeling problems. We explore two approaches, an intrinsic Gaussian processes classification technique and a probit treatment of the Gaussian processes regression method. Here, we describe the basic concepts of the methods and apply these techniques to building category models of absorption, distribution, metabolism, excretion, toxicity and target activity data. We also compare the performance of Gaussian processes for classification to other known computational methods, namely decision trees, random forest, support vector machines, and probit partial least squares. The results indicate that, while no method consistently generates the best model, the Gaussian processes classifier often produces more predictive models than those of the random forest or support vector machines and was rarely significantly outperformed.},
author = {Obrezanova, Olga and Segall, Matthew D.},
doi = {10.1021/ci900406x},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci900406x.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {6},
pages = {1053--1061},
title = {{Gaussian processes for classification: QSAR modeling of ADMET and target activity}},
volume = {50},
year = {2010}
}
@article{Smieja2018,
abstract = {We propose a general, theoretically justified mechanism for processing missing data by neural networks. Our idea is to replace typical neuron's response in the first hidden layer by its expected value. This approach can be applied for various types of networks at minimal cost in their modification. Moreover, in contrast to recent approaches, it does not require complete data for training. Experimental results performed on different types of architectures show that our method gives better results than typical imputation strategies and other methods dedicated for incomplete data.},
archivePrefix = {arXiv},
arxivId = {1805.07405},
author = {Smieja, Marek and Struski, {\L}ukasz and Tabor, Jacek and Zieli{\'{n}}ski, Bartosz and Spurek, Przemys{\l}aw},
eprint = {1805.07405},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Processing{\_}of{\_}missing{\_}data{\_}by{\_}neural{\_}networks.pdf:pdf},
month = {may},
number = {May},
title = {{Processing of missing data by neural networks}},
url = {http://arxiv.org/abs/1805.07405},
year = {2018}
}
@article{Lo2018,
author = {Lo, Yu-chen and Rensi, Stefano E and Torng, Wen and Altman, Russ B},
doi = {10.1016/j.drudis.2018.05.010},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S1359644617304695-main.pdf:pdf},
issn = {1359-6446},
journal = {Drug Discovery Today},
number = {8},
pages = {1538--1546},
publisher = {Elsevier Ltd},
title = {{Machine learning in chemoinformatics and drug discovery}},
url = {https://doi.org/10.1016/j.drudis.2018.05.010},
volume = {23},
year = {2018}
}
@article{Marron1987,
author = {Marron, J . S .},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/2241074.pdf:pdf},
journal = {Annals of Statistics},
keywords = {Marron},
mendeley-tags = {Marron},
number = {1},
pages = {152--162},
title = {{A Comparison of Cross-Validation Techniques in Density Estimation}},
volume = {15},
year = {1987}
}
@article{Irwin2020,
author = {Irwin, B.W.J. and Levell, J and Whitehead, T and Segall, M and Conduit, G},
journal = {Journal of Chemical Information and Modeling},
title = {{Practical Applications of Deep Learning to Impute Drug Discovery Data}},
year = {2020}
}
@misc{Munafo,
author = {Munafo, Robert},
booktitle = {RIES - Find Algebraic Equations, Given Their Solution},
title = {{RIES}},
url = {http://mrob.com/pub/ries/index.html},
urldate = {2020-04-13},
year = {1996}
}
@article{Myint2012,
author = {Myint, Kyaw-zeyar and Wang, Lirong and Tong, Qin and Xie, Xiang-qun},
doi = {10.1021/mp300237z},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/mp300237z.pdf:pdf},
issn = {1543-8384},
journal = {Molecular Pharmaceutics},
keywords = {arti fi cial neural,bioactivity prediction,cannabinoid,cb2,molecular fi ngerprints,networks,qsar,virtual screening},
month = {oct},
number = {10},
pages = {2912--2923},
title = {{Molecular Fingerprint-Based Artificial Neural Networks QSAR for Ligand Biological Activity Predictions}},
url = {http://pubs.acs.org/doi/10.1021/mp300237z},
volume = {9},
year = {2012}
}
@article{Segler2018,
abstract = {{\textcopyright} 2018 Macmillan Publishers Limited, part of Springer Nature. All rights reserved. To plan the syntheses of small organic molecules, chemists use retrosynthesis, a problem-solving technique in which target molecules are recursively transformed into increasingly simpler precursors. Computer-aided retrosynthesis would be a valuable tool but at present it is slow and provides results of unsatisfactory quality. Here we use Monte Carlo tree search and symbolic artificial intelligence (AI) to discover retrosynthetic routes. We combined Monte Carlo tree search with an expansion policy network that guides the search, and a filter network to pre-select the most promising retrosynthetic steps. These deep neural networks were trained on essentially all reactions ever published in organic chemistry. Our system solves for almost twice as many molecules, thirty times faster than the traditional computer-aided search method, which is based on extracted rules and hand-designed heuristics. In a double-blind AB test, chemists on average considered our computer-generated routes to be equivalent to reported literature routes.},
author = {Segler, Marwin H.S. and Preuss, Mike and Waller, Mark P.},
doi = {10.1038/nature25978},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/nature25978.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7698},
pages = {604--610},
publisher = {Nature Publishing Group},
title = {{Planning chemical syntheses with deep neural networks and symbolic AI}},
url = {http://dx.doi.org/10.1038/nature25978},
volume = {555},
year = {2018}
}
@article{Zakharov2014,
abstract = {We describe a novel approach to RBF approximation, which combines two new elements: (1) linear radial basis functions and (2) weighting the model by each descriptor's contribution. Linear radial basis functions allow one to achieve more accurate predictions for diverse data sets. Taking into account the contribution of each descriptor produces more accurate similarity values used for model development. The method was validated on 14 public data sets comprising nine physicochemical properties and five toxicity endpoints. We also compared the new method with five different QSAR methods implemented in the EPA T.E.S.T. program. Our approach, implemented in the program GUSAR, showed a reasonable accuracy of prediction and high coverage for all external test sets, providing more accurate prediction results than the comparison methods and even the consensus of these methods. Using our new method, we have created models for physicochemical and toxicity endpoints, which we have made freely available in the form of an online service at http://cactus.nci.nih.gov/chemical/apps/cap .},
author = {Zakharov, Alexey V. and Peach, Megan L. and Sitzmann, Markus and Nicklaus, Marc C.},
doi = {10.1021/ci400704f},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci400704f.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {mar},
number = {3},
pages = {713--719},
title = {{A New Approach to Radial Basis Function Approximation and Its Application to QSAR}},
url = {http://pubs.acs.org/doi/10.1021/ci400704f},
volume = {54},
year = {2014}
}
@article{Wright1935,
annote = {doi: 10.1112/jlms/s1-10.40.286},
author = {Wright, E Maitland},
doi = {10.1112/jlms/s1-10.40.286},
issn = {0024-6107},
journal = {Journal of the London Mathematical Society},
month = {oct},
number = {4},
pages = {286--293},
publisher = {Oxford University Press (OUP)},
title = {{The Asymptotic Expansion of the Generalized Hypergeometric Function}},
url = {https://doi.org/10.1112/jlms/s1-10.40.286},
volume = {s1-10},
year = {1935}
}
@article{Ertl2009,
abstract = {Background. A method to estimate ease of synthesis (synthetic accessibility) of drug-like molecules is needed in many areas of the drug discovery process. The development and validation of such a method that is able to characterize molecule synthetic accessibility as a score between 1 (easy to make) and 10 (very difficult to make) is described in this article. Results. The method for estimation of the synthetic accessibility score (SAscore) described here is based on a combination of fragment contributions and a complexity penalty. Fragment contributions have been calculated based on the analysis of one million representative molecules from PubChem and therefore one can say that they capture historical synthetic knowledge stored in this database. The molecular complexity score takes into account the presence of non-standard structural features, such as large rings, non-standard ring fusions, stereocomplexity and molecule size. The method has been validated by comparing calculated SAscores with ease of synthesis as estimated by experienced medicinal chemists for a set of 40 molecules. The agreement between calculated and manually estimated synthetic accessibility is very good with r2 = 0.89. Conclusion. A novel method to estimate synthetic accessibility of molecules has been developed. This method uses historical synthetic knowledge obtained by analyzing information from millions of already synthesized chemicals and considers also molecule complexity. The method is sufficiently fast and provides results consistent with estimation of ease of synthesis by experienced medicinal chemists. The calculated SAscore may be used to support various drug discovery processes where a large number of molecules needs to be ranked based on their synthetic accessibility, for example when purchasing samples for screening, selecting hits from high-throughput screening for follow-up, or ranking molecules generated by various de novo design approaches. {\textcopyright} 2009 Ertl and Schuffenhauer; licensee BioMed Central Ltd.},
author = {Ertl, Peter and Schuffenhauer, Ansgar},
doi = {10.1186/1758-2946-1-8},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/SynthAcc.pdf:pdf},
issn = {17582946},
journal = {Journal of Cheminformatics},
number = {1},
pages = {1--11},
title = {{Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions}},
volume = {1},
year = {2009}
}
@article{Segall2015,
abstract = {All of the experimental compound data with which we work have significant uncertainties, due to imperfect correlations between experimental systems and the ultimate in vivo properties of compounds and the inherent variability in experimental conditions. When using these data to make decisions, it is essential that these uncertainties are taken into account to avoid making inappropriate decisions in the selection of compounds, which can lead to wasted effort and missed opportunities. In this paper we will consider approaches to rigorously account for uncertainties when selecting between compounds or assessing compounds against a property criterion; first for an individual measurement of a single property and then for multiple measurements of a property for the same compound. We will then explore how uncertainties in multiple properties can be combined when assessing compounds against a profile of criteria, a process known as multi-parameter optimisation. This guides rigorous decision-making using complex, uncertain data to focus on compounds with the best chance of success, while avoiding missed opportunities by inappropriately rejecting compounds.},
author = {Segall, Matthew D and Champness, Edmund J},
doi = {10.1007/s10822-015-9855-2},
issn = {1573-4951},
journal = {Journal of Computer-Aided Molecular Design},
month = {sep},
number = {9},
pages = {809--816},
title = {{The challenges of making decisions using uncertain data}},
url = {https://doi.org/10.1007/s10822-015-9855-2},
volume = {29},
year = {2015}
}
@article{Halberstam2003,
author = {Halberstam, Nataliya M and Baskin, Igor I and Palyulin, Vladimir A and Zefirov, Nikolai S},
doi = {10.1070/RC2003v072n07ABEH000754},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Nataliya{\_}M{\_}{\_}Halberstam{\_}2003{\_}Russ.{\_}Chem.{\_}Rev.{\_}72{\_}R04.pdf:pdf},
issn = {0036-021X},
journal = {Russian Chemical Reviews},
month = {jul},
number = {7},
pages = {629--649},
title = {{Neural networks as a method for elucidating structure–property relationships for organic compounds}},
url = {http://stacks.iop.org/0036-021X/72/i=7/a=R04?key=crossref.6ac281213f5537ae08e489172487f322},
volume = {72},
year = {2003}
}
@article{Fukunishi2014,
abstract = {A compound's synthetic accessibility (SA) is an important aspect of drug design, since in some cases computer-designed compounds cannot be synthesized. There have been several reports on SA prediction, most of which have focused on the difficulties of synthetic reactions based on retro-synthesis analyses, reaction databases and the availability of starting materials. We developed a new method of predicting SA using commercially available compound databases and molecular descriptors. SA was estimated from the probability of existence of substructures consisting of the compound in question, the number of symmetry atoms, the graph complexity, and the number of chiral centers of the compound. The probabilities of the existence of given substructures were estimated based on a compound library. The predicted SA results reproduced the expert manual assessments with a Pearson correlation coefficient of 0.56. Since our method required a compound database and not a reaction database, it should be easy to customize the prediction for compound vendors. The correlation between the sales price of approved drugs and the SA values was also examined and found to be weak. The price most likely depends on the total cost of development and other factors.},
author = {Fukunishi, Yoshifumi and Kurosawa, Takashi and Mikami, Yoshiaki and Nakamura, Haruki},
doi = {10.1021/ci500568d},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/SynthAcc2.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {12},
pages = {3259--3267},
title = {{Prediction of synthetic accessibility based on commercially available compound databases}},
volume = {54},
year = {2014}
}
@article{Yang2016,
author = {Yang, Jeremy J and Ursu, Oleg and Lipinski, Christopher A and Sklar, Larry A and Oprea, Tudor I and Bologa, Cristian G},
doi = {10.1186/s13321-016-0137-3},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/s13321-016-0137-3.pdf:pdf},
issn = {1758-2946},
journal = {Journal of Cheminformatics},
keywords = {Compound promiscuity,Drug discovery informatics,High-throughput screening (HTS),Molecular scaffolds,Statistical learning,compound promiscuity,drug discovery informatics,high-throughput screening,hts,molecular,scaffolds,statistical learning},
pages = {1--14},
publisher = {Springer International Publishing},
title = {{Badapple : promiscuity patterns from noisy evidence}},
year = {2016}
}
@article{Barrett2004,
author = {Barrett, S J and Langdon, W B},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/978-3-540-36266-1{\_}10.pdf:pdf},
title = {{Advances in the Application of Machine Learning Techniques in Drug Discovery , Design and Development SVM Applications in Pharmaceuticals Research}},
year = {2004}
}
@incollection{WoldS.;SjostromM.;Eriksson1999,
address = {Chichester, UK},
author = {{Wold, S.; Sjostrom, M.; Eriksson}, L.},
booktitle = {The Encyclopedia of Computational Chemistry},
edition = {III},
editor = {{Schleyer, P., Allinger, N., Clark, T., Gasteiger, J., Kollman, P.}, Schaefer},
keywords = {Wold},
pages = {pp 1−16},
publisher = {John Wiley and Sons.},
title = {{PLS method}},
year = {1999}
}
@article{McCoy2018,
abstract = {Missing data values and differing sampling rates, particularly for important parameters such as particle size and stream composition, are a common problem in minerals processing plants. Missing data imputation is used to avoid information loss (due to downsampling or discarding incomplete records). A recent deep-learning technique, variational autoencoders (VAEs), has been used for missing data imputation in image data, and was compared here to imputation by mean replacement and by principal component analysis (PCA) imputation. The techniques were compared using a synthetic, nonlinear dataset, and a simulated milling circuit dataset, which included process disturbances, measurement noise, and feedback control. Each dataset was corrupted with missing values in 20{\%} of records (lightly corrupted) and in 90{\%} of records (heavily corrupted). For both lightly and heavily corrupted datasets, the root mean squared error of prediction for VAE imputation was lower than the traditional methods. Possibilities for the extension of missing data imputation to inferential sensing are discussed.},
author = {McCoy, John T. and Kroon, Steve and Auret, Lidia},
doi = {10.1016/j.ifacol.2018.09.406},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S2405896318320949-main.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Machine Learning,Missing Data Imputation,Variational Autoencoder},
number = {21},
pages = {141--146},
publisher = {Elsevier B.V.},
title = {{Variational Autoencoders for Missing Data Imputation with Application to a Simulated Milling Circuit}},
url = {https://doi.org/10.1016/j.ifacol.2018.09.406 https://linkinghub.elsevier.com/retrieve/pii/S2405896318320949},
volume = {51},
year = {2018}
}
@article{Azur2011,
author = {Azur, Melissa J and Stuart, Elizabeth A and Frangakis, Constantine and Leaf, Philip J},
doi = {10.1002/mpr.329},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/nihms267760.pdf:pdf},
issn = {10498931},
journal = {International Journal of Methods in Psychiatric Research},
keywords = {analyze,missing data,multiple imputation},
month = {mar},
number = {1},
pages = {40--49},
title = {{Multiple imputation by chained equations: what is it and how does it work?}},
url = {http://doi.wiley.com/10.1002/mpr.329},
volume = {20},
year = {2011}
}
@article{Karpov2011,
author = {Karpov, Pavel V and Osolodkin, Dmitry I and Baskin, Igor I and Palyulin, Vladimir A and Zefirov, Nikolay S},
doi = {10.1016/j.bmcl.2011.09.051},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S0960894X11012959-main.pdf:pdf},
issn = {0960894X},
journal = {Bioorganic {\&} Medicinal Chemistry Letters},
keywords = {one-class classification},
month = {nov},
number = {22},
pages = {6728--6731},
publisher = {Elsevier Ltd},
title = {{One-class classification as a novel method of ligand-based virtual screening: The case of glycogen synthase kinase 3$\beta$ inhibitors}},
url = {http://dx.doi.org/10.1016/j.bmcl.2011.09.051 https://linkinghub.elsevier.com/retrieve/pii/S0960894X11012959},
volume = {21},
year = {2011}
}
@article{Hessler2018,
abstract = {Artificial Intelligence (AI) plays a pivotal role in drug discovery. In particular artificial neural networks such as deep neural networks or recurrent networks drive this area. Numerous applications in property or activity predictions like physicochemical and ADMET properties have recently appeared and underpin the strength of this technology in quantitative structure-property relationships (QSPR) or quantitative structure-activity relationships (QSAR). Artificial intelligence in de novo design drives the generation of meaningful new biologically active molecules towards desired properties. Several examples establish the strength of artificial intelligence in this field. Combination with synthesis planning and ease of synthesis is feasible and more and more automated drug discovery by computers is expected in the near future.},
author = {Hessler, Gerhard and Baringhaus, Karl-Heinz},
doi = {10.3390/molecules23102520},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/0994a2bdde3d50926d966e5bac0bac690037.pdf:pdf},
issn = {1420-3049},
journal = {Molecules},
keywords = {ADME/T,QSAR,artificial intelligence,deep learning,drug design},
month = {oct},
number = {10},
pages = {2520},
title = {{Artificial Intelligence in Drug Design}},
url = {http://link.springer.com/10.1007/s11427-018-9342-2 http://www.mdpi.com/1420-3049/23/10/2520},
volume = {23},
year = {2018}
}
@article{Shah2014,
abstract = {We investigate the Student-t process as an alternative to the Gaussian process as a nonparametric prior over functions. We derive closed form expressions for the marginal likelihood and predictive distribution of a Student-t process, by integrating away an inverse Wishart process prior over the covariance kernel of a Gaussian process model. We show surprising equivalences between different hierarchical Gaussian process models leading to Student-t processes, and derive a new sampling scheme for the inverse Wishart process, which helps elucidate these equivalences. Overall, we show that a Student-t process can retain the attractive properties of a Gaussian process -- a nonparametric representation, analytic marginal and predictive distributions, and easy model selection through covariance kernels -- but has enhanced flexibility, and predictive covariances that, unlike a Gaussian process, explicitly depend on the values of training observations. We verify empirically that a Student-t process is especially useful in situations where there are changes in covariance structure, or in applications like Bayesian optimization, where accurate predictive covariances are critical for good performance. These advantages come at no additional computational cost over Gaussian processes.},
archivePrefix = {arXiv},
arxivId = {1402.4306},
author = {Shah, Amar and Wilson, Andrew Gordon and Ghahramani, Zoubin},
eprint = {1402.4306},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/tprocess.pdf:pdf},
month = {feb},
title = {{Student-t Processes as Alternatives to Gaussian Processes}},
url = {http://arxiv.org/abs/1402.4306},
volume = {33},
year = {2014}
}
@article{Gao2013,
abstract = {Could high-quality in silico predictions in drug discovery eventually replace part or most of experimental testing? To evaluate the agreement of selectivity data from different experimental or predictive sources, we introduce the new metric concordance minimum significant ratio (cMSR). Empowered by cMSR, we find the overall level of agreement between predicted and experimental data to be comparable to that found between experimental results from different sources. However, for molecules that are either highly selective or potent, the concordance between different experimental sources is significantly higher than the concordance between experimental and predicted values. We also show that computational models built from one data set are less predictive for other data sources and highlight the importance of bias correction for assessing selectivity data. Finally, we show that small-molecule target space relationships derived from different data sources and predictive models share overall similarity but can significantly differ in details. {\textcopyright} 2013 American Chemical Society.},
author = {Gao, Cen and Cahya, Suntara and Nicolaou, Christos A. and Wang, Jibo and Watson, Ian A. and Cummins, David J. and Iversen, Philip W. and Vieth, Michal},
doi = {10.1021/jm400798j},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/jm400798j.pdf:pdf},
issn = {0022-2623},
journal = {Journal of Medicinal Chemistry},
month = {sep},
number = {17},
pages = {6991--7002},
title = {{Selectivity Data: Assessment, Predictions, Concordance, and Implications}},
url = {https://pubs.acs.org/doi/10.1021/jm400798j},
volume = {56},
year = {2013}
}
@article{Segler2018a,
abstract = {In de novo drug design, computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work, we show that recurrent neural networks can be trained as generative models for molecular structures, similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active toward a given biological target, we propose to fine-tune the model with small sets of molecules, which are known to be active against that target. Against Staphylococcus aureus, the model reproduced 14{\%} of 6051 hold-out test molecules that medicinal chemists designed, whereas against Plasmodium falciparum (Malaria), it reproduced 28{\%} of 1240 test molecules. When coupled with a scoring function, our model can perform the complete de novo drug design cycle to generate large sets of novel molecules for drug discovery.},
author = {Segler, Marwin H. S. and Kogej, Thierry and Tyrchan, Christian and Waller, Mark P.},
doi = {10.1021/acscentsci.7b00512},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acscentsci.7b00512.pdf:pdf},
issn = {2374-7943},
journal = {ACS Central Science},
month = {jan},
number = {1},
pages = {120--131},
title = {{Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks}},
url = {http://pubs.acs.org/doi/10.1021/acscentsci.7b00512},
volume = {4},
year = {2018}
}
@article{Jiang2018,
abstract = {Artificial Intelligence (AI) plays a pivotal role in drug discovery. In particular artificial neural networks such as deep neural networks or recurrent networks drive this area. Numerous applications in property or activity predictions like physicochemical and ADMET properties have recently appeared and underpin the strength of this technology in quantitative structure-property relationships (QSPR) or quantitative structure-activity relationships (QSAR). Artificial intelligence in de novo design drives the generation of meaningful new biologically active molecules towards desired properties. Several examples establish the strength of artificial intelligence in this field. Combination with synthesis planning and ease of synthesis is feasible and more and more automated drug discovery by computers is expected in the near future.},
author = {Jiang, Hualiang and Chen, Kaixian and Luo, Xiaomin and Wu, Xiaolong and Li, Fei and Xiong, Zhaoping and Lu, Dong and Liu, Xiaohong and Li, Zhaojun and Xing, Jing and Tan, Xiaoqin and Zheng, Mingyue and Fu, Zunyun and Li, Xutong and Zhong, Feisheng and Zhao, Jihui},
doi = {10.1007/s11427-018-9342-2},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Zhong2018{\_}Article{\_}ArtificialIntelligenceInDrugDe.pdf:pdf},
issn = {1674-7305},
journal = {Science China Life Sciences},
keywords = {ADME/T,QSAR,artificial intelligence,deep learning,drug design},
number = {10},
pages = {1191--1204},
title = {{Artificial intelligence in drug design}},
volume = {61},
year = {2018}
}
@article{Sharma2017,
author = {Sharma, Praveen and Singh, Harpreet and Kim, Mi-hyun and Yadav, Dharmendra Kumar and Saloni, Saloni and Misra, Sanjeev and Khan, Feroz and Kumar, Surendra},
doi = {10.2147/dddt.s130601},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/DDDT-130601-molecular-docking--qsar-and-adme-t-studies-of-withania-analo{\_}062217.pdf:pdf},
issn = {11778881},
journal = {Drug Design, Development and Therapy},
keywords = {admet,breast cancer,molecular docking,qsar,withanolides},
pages = {1859--1870},
pmid = {28694686},
title = {{Molecular docking, QSAR and ADMET studies of withanolide analogs against breast cancer}},
volume = {Volume 11},
year = {2017}
}
@book{Bateman1953,
author = {Erdelyi, A. and Bateman, H.},
booktitle = {Bateman Manuscript Project},
title = {{Tables of Integral Transforms I}},
year = {1953}
}
@article{McAllister2013,
author = {McAllister, Fiona E. and Gygi, Steven P},
doi = {10.1016/j.ymeth.2013.03.012},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S1046202313000819-main.pdf:pdf},
issn = {10462023},
journal = {Methods},
month = {jun},
number = {3},
pages = {227--235},
publisher = {Elsevier Inc.},
title = {{Correlation profiling for determining kinase-substrate relationships}},
url = {http://dx.doi.org/10.1016/j.ymeth.2013.03.012 https://linkinghub.elsevier.com/retrieve/pii/S1046202313000819},
volume = {61},
year = {2013}
}
@article{Simm2017,
abstract = {Bayesian matrix factorization is a method of choice for making predictions for large-scale incomplete matrices, due to availability of efficient Gibbs sampling schemes and its robustness to overfitting. In this paper, we consider factorization of large scale matrices with high-dimensional side information. However, sampling the link matrix for the side information with standard approaches costs O(F3) time, where F is the dimensionality of the features. To overcome this limitation we, firstly, propose a prior for the link matrix whose strength is proportional to the scale of latent variables. Secondly, using this prior we derive an efficient sampler, with linear complexity in the number of non-zeros, O(Nnz), by leveraging Krylov subspace methods, such as block conjugate gradient, allowing us to handle million-dimensional side information. We demonstrate the effectiveness of our proposed method in drug-protein interaction prediction task.},
author = {Simm, J. and Arany, A. and Zakeri, P. and Haber, T. and Wegner, J. K. and Chupakhin, V. and Ceulemans, H. and Moreau, Y.},
doi = {10.1109/MLSP.2017.8168143},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/macau.pdf:pdf},
isbn = {9781509063413},
issn = {21610371},
journal = {IEEE International Workshop on Machine Learning for Signal Processing, MLSP},
keywords = {High scale machine learning,MCMC,Matrix factorization,Side information},
pages = {1--6},
title = {{Macau: Scalable Bayesian factorization with high-dimensional side information using MCMC}},
volume = {2017-Septe},
year = {2017}
}
@article{Chen2018,
abstract = {Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis.},
author = {Chen, Hongming and Engkvist, Ola and Wang, Yinhai and Olivecrona, Marcus and Blaschke, Thomas},
doi = {10.1016/j.drudis.2018.01.039},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S1359644617303598-main.pdf:pdf},
issn = {18785832},
journal = {Drug Discovery Today},
number = {6},
pages = {1241--1250},
publisher = {Elsevier Ltd},
title = {{The rise of deep learning in drug discovery}},
url = {https://doi.org/10.1016/j.drudis.2018.01.039},
volume = {23},
year = {2018}
}
@article{Tetko1995,
author = {Tetko, Igor V and Livingstone, David J. and Luik, Alexander I.},
doi = {10.1021/ci00027a006},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci00027a006.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {sep},
number = {5},
pages = {826--833},
title = {{Neural network studies. 1. Comparison of overfitting and overtraining}},
url = {http://pubs.acs.org/doi/abs/10.1021/ci00027a006},
volume = {35},
year = {1995}
}
@article{Sleight2020,
abstract = {We propose a Mellin space approach to the evaluation of late-time momentum-space correlation functions of quantum fields in (d + 1)-dimensional de Sitter space. The Mellin-Barnes representation makes manifest the analytic structure of late-time correlators and, more generally, provides a convenient general d framework for the study of conformal correlators in momentum space. In this work we focus on tree-level correlation functions of general scalars as a prototype, including n-point contact diagrams and 4-point exchanges. For generic scalars, both the contact and exchange diagrams are given by (generalised) Hypergeometric functions, which reduce to existing expressions available in the literature for d = 3 and external scalars which are either simultaneously conformally coupled or massless. This approach can also be used for the perturbative bulk evaluation of momentum space boundary correlators in (d + 1)-dimensional anti-de Sitter space (Witten diagrams).},
archivePrefix = {arXiv},
arxivId = {1906.12302},
author = {Sleight, Charlotte},
doi = {10.1007/JHEP01(2020)090},
eprint = {1906.12302},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/Cosmology.pdf:pdf},
issn = {10298479},
journal = {Journal of High Energy Physics},
keywords = {AdS-CFT Correspondence,Conformal and W Symmetry,Scattering Amplitudes},
number = {1},
title = {{A Mellin space approach to cosmological correlators}},
volume = {2020},
year = {2020}
}
@misc{KdF,
author = {{Kamp{\'{e}} de F{\'{e}}riet}, J},
howpublished = {85 p. M{\'{e}}m. Sci. math. 85 (1937).},
title = {{La fonction hyperg{\'{e}}om{\'{e}}trique.}},
year = {1937}
}
@article{Yehuda2009,
author = {Yehuda, Koren and Robert, Bell and Chris, Yolinsky},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Recommender-Systems-[Netflix].pdf:pdf},
journal = {IEEE Computer Society},
pages = {1--8},
title = {{Matrixfactorizationtechniques Forrecommendersystems}},
year = {2009}
}
@misc{Plouffe1986,
author = {Plouffe, Simon},
title = {{Inverse Symbolic Calculator}},
url = {http://www.plouffe.fr/simon/inverter.txt},
year = {1986}
}
@article{Bosc2019,
abstract = {Structure–activity relationship modelling is frequently used in the early stage of drug discovery to assess the activity of a compound on one or several targets, and can also be used to assess the interaction of compounds with liability targets. QSAR models have been used for these and related applications over many years, with good success. Conformal prediction is a relatively new QSAR approach that provides information on the certainty of a prediction, and so helps in decision-making. However, it is not always clear how best to make use of this additional information. In this article, we describe a case study that directly compares conformal prediction with traditional QSAR methods for large-scale predictions of target-ligand binding. The ChEMBL database was used to extract a data set comprising data from 550 human protein targets with different bioactivity profiles. For each target, a QSAR model and a conformal predictor were trained and their results compared. The models were then evaluated on new data published since the original models were built to simulate a “real world” application. The comparative study highlights the similarities between the two techniques but also some differences that it is important to bear in mind when the methods are used in practical drug discovery applications.},
author = {Bosc, Nicolas and Atkinson, Francis and Felix, Eloy and Gaulton, Anna and Hersey, Anne and Leach, Andrew R.},
doi = {10.1186/s13321-018-0325-4},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/s13321-018-0325-4.pdf:pdf},
issn = {17582946},
journal = {Journal of Cheminformatics},
keywords = {ChEMBL,Cheminformatics,Classification models,Mondrian conformal prediction,QSAR},
number = {1},
pages = {1--16},
publisher = {Springer International Publishing},
title = {{Large scale comparison of QSAR and conformal prediction methods and their applications in drug discovery}},
url = {https://doi.org/10.1186/s13321-018-0325-4},
volume = {11},
year = {2019}
}
@article{Hu2018,
author = {Hu, Qiwan and Feng, Mudong and Lai, Luhua and Pei, Jianfeng},
doi = {10.3389/fgene.2018.00585},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/fgene-09-00585.pdf:pdf},
keywords = {auto-encoder,deep learning,drug-likeness,drug-likeness, ZINC, MDDR, deep learning, auto-enc,mddr,zinc},
number = {November},
pages = {1--8},
title = {{Prediction of Drug-Likeness Using Deep Autoencoder Neural Networks}},
volume = {9},
year = {2018}
}
@article{Irwin2018,
abstract = {{\textcopyright} 2018 The Authors. Proteins: Structure, Function, and Bioinformatics published by Wiley Periodicals, Inc. We have performed docking simulations on GABARAP interacting with the GABA type A receptor using SwarmDock. We have also used a novel method to study hydration sites on the surface of these two proteins; this method identifies regions around proteins where desolvation is relatively easy, and these are possible locations where proteins can bind each other. There is a high degree of consistency between the predictions of these two methods. Moreover, we have also identified binding sites on GABARAP for other proteins, and listed possible binding sites for as yet unknown proteins on both GABARAP and the GABA type A receptor intracellular domain.},
author = {Irwin, B.W.J. and Vukovi{\v{c}}, S. and Payne, M.C. and ElGamacy, M. and Chau, P.-L.},
doi = {10.1002/prot.25589},
issn = {10970134},
journal = {Proteins: Structure, Function and Bioinformatics},
keywords = {GABA  receptor A,GABARAP,free energy change},
number = {12},
title = {{Prediction of GABARAP interaction with the GABA type A receptor}},
volume = {86},
year = {2018}
}
@article{Eklund2012,
abstract = {QSAR modeling is a method for predicting properties, e.g. the solubility or toxicity, of chemical compounds using statistical learning techniques. QSAR is in widespread use within the pharmaceutical industry to prioritize compounds for experimental testing or to alert for potential toxicity. However, predictions from a QSAR model are difficult to assess if their prediction intervals are unknown. In this paper we introduce conformal prediction into the QSAR field to address this issue. We apply support vector machine regression in combination with two nonconformity measures to five datasets of different sizes to demonstrate the usefulness of conformal prediction in QSAR modeling. One of the nonconformity measures provides prediction intervals with almost the same width as the size of the QSAR models' prediction errors, showing that the prediction intervals obtained by conformal prediction are efficient and useful. {\textcopyright} 2012 IFIP International Federation for Information Processing.},
author = {Eklund, Martin and Norinder, Ulf and Boyer, Scott and Carlsson, Lars},
doi = {10.1007/978-3-642-33412-2_17},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Eklund2012{\_}Chapter{\_}ApplicationOfConformalPredicti.pdf:pdf},
isbn = {9783642334115},
issn = {18684238},
journal = {IFIP Advances in Information and Communication Technology},
number = {PART 2},
pages = {166--175},
title = {{Application of conformal prediction in QSAR}},
volume = {382 AICT},
year = {2012}
}
@article{Bento2014,
abstract = {ChEMBL is an open large-scale bioactivity database (https://www.ebi.ac.uk/ chembl), previously described in the 2012 Nucleic Acids Research Database Issue. Since then, a variety of new data sources and improvements in functionality have contributed to the growth and utility of the resource. In particular, more comprehensive tracking of compounds from research stages through clinical development to market is provided through the inclusion of data from United States Adopted Name applications; a new richer data model for representing drug targets has been developed; and a number of methods have been put in place to allow users to more easily identify reliable data. Finally, access to ChEMBL is now available via a new Resource Description Framework format, in addition to the web-based interface, data downloads and web services. {\textcopyright} 2013 The Author(s). Published by Oxford University Press.},
author = {Bento, A. Patr{\'{i}}cia and Gaulton, Anna and Hersey, Anne and Bellis, Louisa J. and Chambers, Jon and Davies, Mark and Kr{\"{u}}ger, Felix A. and Light, Yvonne and Mak, Lora and McGlinchey, Shaun and Nowotka, Michal and Papadatos, George and Santos, Rita and Overington, John P.},
doi = {10.1093/nar/gkt1031},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/gkt1031.pdf:pdf},
issn = {0305-1048},
journal = {Nucleic Acids Research},
month = {jan},
number = {D1},
pages = {D1083--D1090},
title = {{The ChEMBL bioactivity database: an update}},
url = {https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkt1031},
volume = {42},
year = {2014}
}
@article{Bergstra2011,
abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel ap-proaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it pos-sible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neu-ral networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the ex-pected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreli-able for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Bergstra, James and Bardenet, R{\'{e}}mi and Bengio, Yoshua and K{\'{e}}gl, Bal{\'{a}}zs},
doi = {2012arXiv1206.2944S},
eprint = {1206.2944},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/4443-algorithms-for-hyper-parameter-optimization.pdf:pdf},
isbn = {9781618395993},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2546--2554},
pmid = {9377276},
title = {{Algorithms for Hyper-Parameter Optimization}},
year = {2011}
}
@article{Ghasemi,
author = {Ghasemi, Fahimeh and Mehri, Alireza and Pe{\~{n}}a-garc{\'{i}}a, Jorge},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Ghasemi2015{\_}Chapter{\_}ImprovingActivityPredictionOfA.pdf:pdf},
keywords = {classification,clustering,genetic algorithm,k-means,one-},
pages = {635--644},
title = {{Improving Activity Prediction of Adenosine A 2B Receptor Antagonists by Nonlinear Models}}
}
@article{Hunt2018,
abstract = {In the development of novel pharmaceuticals, the knowledge of how many, and which, Cytochrome P450 isoforms are involved in the phase I metabolism of a compound is important. Potential problems can arise if a compound is metabolised predominantly by a single isoform in terms of drug--drug interactions or genetic polymorphisms that would lead to variations in exposure in the general population. Combined with models of regioselectivities of metabolism by each isoform, such a model would also aid in the prediction of the metabolites likely to be formed by P450-mediated metabolism. We describe the generation of a multi-class random forest model to predict which, out of a list of the seven leading Cytochrome P450 isoforms, would be the major metabolising isoforms for a novel compound. The model has a 76{\%} success rate with a top-1 criterion and an 88{\%} success rate for a top-2 criterion and shows significant enrichment over randomised models.},
author = {Hunt, Peter A and Segall, Matthew D and Tyzack, Jonathan D},
doi = {10.1007/s10822-018-0107-0},
issn = {1573-4951},
journal = {Journal of Computer-Aided Molecular Design},
month = {apr},
number = {4},
pages = {537--546},
title = {{WhichP450: a multi-class categorical model to predict the major metabolising CYP450 isoform for a compound}},
url = {https://doi.org/10.1007/s10822-018-0107-0},
volume = {32},
year = {2018}
}
@misc{,
title = {{Constellation Pharmaceuticals}},
url = {https://www.constellationpharma.com/},
urldate = {2019-12-16}
}
@article{Varnek2009,
author = {Varnek, Alexandre and Marcou, Gilles and Baskin, Igor and Pandey, Anil Kumar},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci8002914.pdf:pdf},
pages = {133--144},
title = {{Inductive Transfer of Knowledge : Application of Multi-Task Learning and Feature Net Approaches to Model Tissue-Air Partition Coefficients}},
year = {2009}
}
@article{Shafer2008,
abstract = {Conformal prediction uses past experience to determine precise levels of confidence in new predictions. Given an error probability $\epsilon$, together with a method that makes a prediction ŷ of a label y, it produces a set of labels, typically containing ŷ, that also contains y with probability 1 - e. Conformal prediction can be applied to any method for producing ŷ. a nearest-neighbor method, a support-vector machine, ridge regression, etc. Conformal prediction is designed for an on-line setting in which labels are predicted successively, each one being revealed before the next is predicted. The most novel and valuable feature of conformal prediction is that if the successive examples are sampled independently from the same distribution, then the successive predictions will be right 1 - $\epsilon$ of the time, even though they are based on an accumulating data set rather than on independent data sets. In addition to the model under which successive examples are sampled independently, other on-line compression models can also use conformal prediction. The widely used Gaussian linear model is one of these. This tutorial presents a self-contained account of the theory of conformal prediction and works through several numerical examples. A more comprehensive treatment of the topic is provided in Algorithmic Learning in a Random World, by Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005).},
archivePrefix = {arXiv},
arxivId = {0706.3188},
author = {Shafer, Glenn and Vovk, Vladimir},
eprint = {0706.3188},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/shafer08a.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Confidence,On-line compression modeling,On-line learning,Prediction regions,Shafer},
mendeley-tags = {Shafer},
pages = {371--421},
title = {{A tutorial on conformal prediction}},
volume = {9},
year = {2008}
}
@article{Obrezanova2007,
abstract = {In this article, we discuss the application of the Gaussian Process method for the prediction of absorption, distribution, metabolism, and excretion (ADME) properties. On the basis of a Bayesian probabilistic approach, the method is widely used in the field of machine learning but has rarely been applied in quantitative structure-activity relationship and ADME modeling. The method is suitable for modeling nonlinear relationships, does not require subjective determination of the model parameters, works for a large number of descriptors, and is inherently resistant to overtraining. The performance of Gaussian Processes compares well with and often exceeds that of artificial neural networks. Due to these features, the Gaussian Processes technique is eminently suitable for automatic model generationsone of the demands of modern drug discovery. Here, we describe the basic concept of the method in the context of regression problems and illustrate its application to the modeling of several ADME properties: blood-brain barrier, hERG inhibition, and aqueous solubility at pH 7.4. We also compare Gaussian Processes with other modeling techniques.},
author = {Obrezanova, Olga and Cs{\'{a}}nyi, G{\'{a}}bor and Gola, Joelle M.R. and Segall, Matthew D.},
doi = {10.1021/ci7000633},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci7000633.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {5},
pages = {1847--1857},
title = {{Gaussian processes: A method for automatic QSAR modeling of ADME properties}},
volume = {47},
year = {2007}
}
@article{Conduit2018,
author = {Conduit, B.D. and Jones, N.G. and Stone, H.J. and Conduit, G.J.},
doi = {10.1016/j.scriptamat.2017.11.008},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ConduitJonesStoneConduit17ii.pdf:pdf},
issn = {13596462},
journal = {Scripta Materialia},
keywords = {Forging,Mechanical properties,Modeling,Neural network,Refractory metals},
month = {mar},
pages = {82--86},
title = {{Probabilistic design of a molybdenum-base alloy using a neural network}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S135964621730653X},
volume = {146},
year = {2018}
}
@article{Scannell2016,
author = {Scannell, Jack W and Bosley, Jim},
doi = {10.1371/journal.pone.0147215},
editor = {Gasparini, Mauro},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/journal.pone.0147215.PDF:PDF},
issn = {1932-6203},
journal = {PLOS ONE},
month = {feb},
number = {2},
pages = {e0147215},
title = {{When Quality Beats Quantity: Decision Theory, Drug Discovery, and the Reproducibility Crisis}},
url = {https://dx.plos.org/10.1371/journal.pone.0147215},
volume = {11},
year = {2016}
}
@article{Shahlaei2010,
author = {Shahlaei, Mohsen and Sabet, Razieh and Ziari, Maryam Bahman and Moeinifard, Behzad and Fassihi, Afshin and Karbakhsh, Reza},
doi = {10.1016/j.ejmech.2010.07.010},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S0223523410004903-main.pdf:pdf},
issn = {02235234},
journal = {European Journal of Medicinal Chemistry},
month = {oct},
number = {10},
pages = {4499--4508},
publisher = {Elsevier Masson SAS},
title = {{QSAR study of anthranilic acid sulfonamides as inhibitors of methionine aminopeptidase-2 using LS-SVM and GRNN based on principal components}},
url = {http://dx.doi.org/10.1016/j.ejmech.2010.07.010 https://linkinghub.elsevier.com/retrieve/pii/S0223523410004903},
volume = {45},
year = {2010}
}
@article{Baba2018,
abstract = {Synthetic accessibility evaluation is a process to assess the ease of synthesis of compounds. A rapid method for the assessment of synthetic accessibility for a vast number of chemical compounds is expected to bring about a breakthrough in the drug discovery. Although several computational methods have been proposed, the compound evaluation has still been processed by medicinal chemists; however, the low throughput of the human evaluation due to the lack of chemists is a critical issue for handling a large number of compounds. We propose the use of crowdsourcing for addressing this problem, and we conducted experiments to investigate the feasibility of incorporating semi-experts and a statistical aggregation method into the synthetic accessibility evaluation. Our experimental results show that we can obtain accurate synthetic accessibility scores through the statistical aggregation of judgments from semi-experts.},
author = {Baba, Yukino and Isomura, Tetsu and Kashima, Hisashi},
doi = {10.1016/j.jmgm.2018.01.011},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1-s2.0-S1093326317306575-main.pdf:pdf},
issn = {18734243},
journal = {Journal of Molecular Graphics and Modelling},
keywords = {Crowdsourcing,Synthetic accessibility},
pages = {217--223},
publisher = {Elsevier Inc.},
title = {{Wisdom of crowds for synthetic accessibility evaluation}},
url = {http://dx.doi.org/10.1016/j.jmgm.2018.01.011},
volume = {80},
year = {2018}
}
@article{Sheridan2013,
annote = {doi: 10.1021/ci400084k},
author = {Sheridan, Robert P},
doi = {10.1021/ci400084k},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {apr},
number = {4},
pages = {783--790},
publisher = {American Chemical Society},
title = {{Time-Split Cross-Validation as a Method for Estimating the Goodness of Prospective Prediction.}},
url = {https://doi.org/10.1021/ci400084k},
volume = {53},
year = {2013}
}
@article{Belisle2015,
abstract = {A knowledge of the physical properties of materials as a function of temperature, composition, applied external stresses, etc. is an important consideration in materials and process design. For new systems, such properties may be unknown and hard to measure or estimate from numerical simulations such as molecular dynamics. Engineers rely on machine learning to employ existing data in order to predict properties for new systems. Several techniques are currently used for such purposes. These include neural network, polynomial interpolation and Gaussian processes as well as the more recent dynamic trees and scalable Gaussian processes. In this paper we compare these approaches for three sets of materials sciences data: molar volume, electrical conductivity and Martensite start temperature. We make recommendations depending on the nature of the data. We demonstrate that a thorough knowledge of the problem beforehand is critical in selecting the most successful machine learning technique. Our findings show that the Gaussian process regression technique gives very good predictions for all three sets of tested data. Typically, Gaussian process is very slow with a computational complexity of typically n3 where n is the number of data points. In this paper, we found that the scalable Gaussian process approach was able to maintain the high accuracy of the predictions while improving speed considerably, make on-line learning possible.},
author = {B{\'{e}}lisle, Eve and Huang, Zi and {Le Digabel}, S{\'{e}}bastien and Gheribi, A{\"{i}}men E},
doi = {https://doi.org/10.1016/j.commatsci.2014.10.032},
issn = {0927-0256},
journal = {Computational Materials Science},
keywords = {Computational dependence,Database,Gaussian process,Neural network,Physical properties,Quadratic regression,Superalloys},
pages = {170--177},
title = {{Evaluation of machine learning interpolation techniques for prediction of physical properties}},
url = {http://www.sciencedirect.com/science/article/pii/S092702561400706X},
volume = {98},
year = {2015}
}
@article{Carvalho2019,
abstract = {Machine learning systems are becoming increasingly ubiquitous. These systems's adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
author = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
doi = {10.3390/electronics8080832},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/electronics-08-00832.pdf:pdf},
issn = {20799292},
journal = {Electronics (Switzerland)},
keywords = {Explainability,Interpretability,Machine learning,XAI},
number = {8},
pages = {1--34},
title = {{Machine learning interpretability: A survey on methods and metrics}},
volume = {8},
year = {2019}
}
@article{Rosasco2004,
abstract = {In this letter, we investigate the impact of choosing different loss functions from the viewpoint of statistical learning theory. We introduce a convexity assumption, which is met by all loss functions commonly used in the literature, and study how the bound on the estimation error changes with the loss. We also derive a general result on the minimizer of the expected risk for a convex loss function in the case of classification. The main outcome of our analysis is that for classification, the hinge loss appears to be the loss of choice. Other things being equal, the hinge loss leads to a convergence rate practically indistinguishable from the logistic loss rate and much better than the square loss rate. Furthermore, if the hypothesis space is sufficiently rich, the bounds obtained for the hinge loss are not loosened by the thresholding stage.},
author = {Rosasco, Lorenzo and Vito, Ernesto De and Caponnetto, Andrea and Piana, Michele and Verri, Alessandro},
doi = {10.1162/089976604773135104},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/loss.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {may},
number = {5},
pages = {1063--1076},
title = {{Are Loss Functions All the Same?}},
url = {http://www.mitpressjournals.org/doi/10.1162/089976604773135104},
volume = {16},
year = {2004}
}
@article{Ruder2016,
abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
archivePrefix = {arXiv},
arxivId = {1609.04747},
author = {Ruder, Sebastian},
eprint = {1609.04747},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1609.04747.pdf:pdf},
month = {sep},
pages = {1--14},
title = {{An overview of gradient descent optimization algorithms}},
url = {http://arxiv.org/abs/1609.04747},
year = {2016}
}
@incollection{Clifford2018,
author = {Clifford, Joan and Reisinger, Deborah S.},
booktitle = {Community-Based Language Learning},
doi = {10.2307/j.ctv7cjw41.5},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/lecun-88.pdf:pdf},
pages = {5--26},
publisher = {Georgetown University Press},
title = {{A Theoretical Framework for CBLL}},
url = {http://www.jstor.org/stable/10.2307/j.ctv7cjw41.5},
year = {2018}
}
@misc{,
abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure.},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/backprop{\_}old.pdf:pdf},
title = {{Backprop{\_}Old.Pdf}}
}
@article{Greenfeld2019,
abstract = {We investigate the use of a non-parametric independence measure, the Hilbert-Schmidt Independence Criterion (HSIC), as a loss-function for learning robust regression and classification models. This loss-function encourages learning models where the distribution of the residuals between the label and the model prediction is statistically independent of the distribution of the instances themselves. This loss-function was first proposed by Mooij et al. (2009) in the context of learning causal graphs. We adapt it to the task of learning for unsupervised covariate shift: learning on a source domain without access to any instances or labels from the unknown target domain, but with the assumption that {\$}p(y|x){\$} (the conditional probability of labels given instances) remains the same in the target domain. We show that the proposed loss is expected to give rise to models that generalize well on a class of target domains characterised by the complexity of their description within a reproducing kernel Hilbert space. Experiments on unsupervised covariate shift tasks demonstrate that models learned with the proposed loss-function outperform models learned with standard loss functions, achieving state-of-the-art results on a challenging cell-microscopy unsupervised covariate shift task.},
archivePrefix = {arXiv},
arxivId = {1910.00270},
author = {Greenfeld, Daniel and Shalit, Uri},
eprint = {1910.00270},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1910.00270.pdf:pdf},
month = {oct},
number = {1},
pages = {1--25},
title = {{Robust Learning with the Hilbert-Schmidt Independence Criterion}},
url = {http://arxiv.org/abs/1910.00270},
year = {2019}
}
@article{Fikioris2006,
abstract = {This is a tutorial presentation of the Mellin-transform (MT) method for the exact calculation of one-dimensional definite integrals, and an illustration of the application of this method to antenna/electromagnetics problems. Once the basics have been mastered, one quickly realizes that the MT-method is extremely powerful, often yielding closed-form expressions very difficult to come up with other methods or to deduce from the usual tables of integrals. Yet, as opposed to other methods, the MT-method is very straightforward to apply; it usually requires laborious calculations, but little ingenuity. In fact, the MT-method is used by Mathematica to symbolically calculate definite integrals. The first part of this paper is a step-by-step tutorial, proceeding from first principles. It includes basic information on Mellin-Barnes integrals and generalized hypergeometric functions, and summarizes the key ideas of the MT-method. In the remaining parts, the MT-method is applied to three examples from the antenna area. The results here are believed to be new, at least in the antenna/electromagnetics literature. In our first example, we obtain a closed-form expression, as a generalized hypergeometric function, for the power radiated by a constant-current circular-loop antenna; this quantity has been extensively discussed recently. Our second example concerns the admittance of a 2-D slot antenna. In both these examples, the exact closed-form expressions are applied to improve upon existing formulas in standard antenna textbooks. In our third example, finally, we obtain a very simple expression for an integral arising in recent, unpublished studies of unbounded, biaxially anisotropic media. {\textcopyright} 2006 IEEE.},
author = {Fikioris, George},
doi = {10.1109/TAP.2006.886579},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/Mellin.pdf:pdf},
issn = {0018926X},
journal = {IEEE Transactions on Antennas and Propagation},
keywords = {Antenna theory,Integration (mathematics),Mellin transforms},
number = {12},
pages = {3895--3907},
title = {{Integral evaluation using the mellin transform and generalized hypergeometric functions: Tutorial and applications to antenna problems}},
volume = {54},
year = {2006}
}
@article{Mainardi2003,
abstract = {The 1888 paper by Salvatore Pincherle (Professor of Mathematics at the University of Bologna) on generalized hypergeometric functions is revisited. We point out the pioneering contribution of the Italian mathematician towards the Mellin-Barnes integrals based on the duality principle between linear differential equations and linear difference equation with rational coefficients. By extending the original arguments used by Pincherle, we also show how to formally derive the linear differential equation and the Mellin-Barnes integral representation of the Meijer G functions. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Mainardi, Francesco and Pagnini, Gianni},
doi = {10.1016/S0377-0427(02)00609-X},
file = {:C$\backslash$:/Users/ben/Downloads/1-s2.0-S037704270200609X-main.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {Generalized hypergeometric functions,Linear difference equations,Linear differential equations,Meijer G-functions,Mellin-Barnes integrals},
number = {1-2},
pages = {331--342},
title = {{Salvatore Pincherle: The pioneer of the Mellin-Barnes integrals}},
volume = {153},
year = {2003}
}
@article{Spataru2007,
author = {Spataru, Silvia and Academy, Taru and Studies, Economic},
file = {:C$\backslash$:/Users/ben/Downloads/Applying{\_}the{\_}Moment{\_}Generating{\_}Functions{\_}to{\_}the{\_}St.pdf:pdf},
issn = {1453-1305},
journal = {Informatica Economica Journal},
keywords = {central,moment generating function,probability density function,probability distribution},
number = {2},
pages = {132--137},
title = {{Applying the Moment Generating Functions to the Study of Probability Distributions}},
volume = {11},
year = {2007}
}
@article{Wahba2003,
abstract = {We review some of the basic facts about reproducing kernel Hilbert spaces (RKHS), and the solution of optimization problems in RKHS, These facts provide some clues to how useful RKHS-based methods can be in curve fitting, function estimation, model description, model fitting and ill-posed inverse problems. A number of references are made to mostly older works of the author, colleagues and former students - not an attempt at a balanced review of the literature. The growth of the further development and application of RKHS based methods is demonstrated in the other papers in the invited Session INV-2 of this 13th IFAC Symposium on System Identification (SYSID-2003), and elsewhere in SISID-2003. A recent advanced google search for "reproducing kernel" turned up over 4400 entries.},
author = {Wahba, Grace},
doi = {https://doi.org/10.1016/S1474-6670(17)34815-2},
issn = {1474-6670},
journal = {IFAC Proceedings Volumes},
keywords = {RKHS,bias-variance tradeoff,ill-posed inverse problems,optimization,representers,reproducing kernel Hilbert spaces,tuning parameters},
number = {16},
pages = {525--528},
title = {{An introduction to reproducing kernel hilbert spaces and why they are so useful}},
url = {http://www.sciencedirect.com/science/article/pii/S1474667017348152},
volume = {36},
year = {2003}
}
@article{Waller1995,
abstract = {[We review and discuss numerical inversion of the characteristic function as a tool for obtaining cumulative distribution functions. With the availability of high-speed computing and symbolic computation software, the method is ideally suited for instructional purposes, particularly in the illustration of the inversion theorems covered in graduate probability courses. The method is also available as an alternative to asymptotic approximations, Monte Carlo, or bootstrap techniques when analytic expressions for the distribution function are not available. We illustrate the method with several examples, including one which is concerned with the detection of possible clusters of disease in an epidemiologic study.]},
author = {Waller, Lance A and Turnbull, Bruce W and Hardin, J Michael},
doi = {10.2307/2684571},
issn = {00031305},
journal = {The American Statistician},
month = {apr},
number = {4},
pages = {346--350},
publisher = {[American Statistical Association, Taylor {\&} Francis, Ltd.]},
title = {{Obtaining Distribution Functions by Numerical Inversion of Characteristic Functions with Applications}},
url = {http://www.jstor.org/stable/2684571},
volume = {49},
year = {1995}
}
@article{Twamley2006,
abstract = {We uncover a new type of unitary operation for quantum mechanics on the half-line which yields a transformation to 'hyperbolic phase space' ($\eta$, p$\eta$). We show that this new unitary change of basis from the position x on the half line to the hyperbolic momentum p$\eta$, transforms the wavef unction via a Mellin transform on to the critical line s = 1 /2 -ip$\eta$. We utilize this new transform to find quantum wavefunctions whose hyperbolic momentum representation approximate a class of higher transcendental functions, and in particular, approximate the Riemann-Zeta function. We finally give possible physical realizations to perform an indirect measurement of the hyperbolic momentum of a quantum system on the half-line. {\textcopyright} IOP Publishing Ltd and Deutsche Physikalische Gesellschaft.},
author = {Twamley, J. and Milburn, G. J.},
doi = {10.1088/1367-2630/8/12/328},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/Twamley{\_}2006{\_}New{\_}J.{\_}Phys.{\_}8{\_}328.pdf:pdf},
issn = {13672630},
journal = {New Journal of Physics},
title = {{The quantum Mellin transform}},
volume = {8},
year = {2006}
}
@article{Fitzpatrick2011,
abstract = {We provide dramatic evidence that 'Mellin space' is the natural home for corre- lation functions in CFTs with weakly coupled bulk duals. In Mellin space, CFT correlators have poles corresponding to an OPE decomposition into 'left' and 'right' sub-correlators, in direct analogy with the factorization channels of scattering amplitudes. In the regime where these correlators can be computed by tree level Witten diagrams in AdS, we derive an explicit formula for the residues of Mellin amplitudes at the corresponding factorization poles, and we use the conformal Casimir to show that these amplitudes obey algebraic finite difference equations. By analyzing the recursive structure of our factorization formula we obtain simple diagrammatic rules for the construction of Mellin amplitudes corresponding to tree-level Witten diagrams in any bulk scalar theory. We prove the diagrammatic rules using our finite difference equations. Finally, we show that our factorization formula and our diagrammatic rules morph into the at space S-Matrix of the bulk theory, reproduc- ing the usual Feynman rules, when we take the at space limit of AdS/CFT. Throughout we emphasize a deep analogy with the properties of at space scattering amplitudes in momentum space, which suggests that the Mellin amplitude may provide a holographic definition of the at space S-Matrix. {\textcopyright} SISSA 2011.},
archivePrefix = {arXiv},
arxivId = {1107.1499},
author = {Fitzpatrick, A. Liam and Kaplan, Jared and Penedones, Joao and Raju, Suvrat and {Van Rees}, Balt C.},
doi = {10.1007/JHEP11(2011)095},
eprint = {1107.1499},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/slac-pub-14506.pdf:pdf},
issn = {11266708},
journal = {Journal of High Energy Physics},
keywords = {AdS-CFT correspondence,Conformal field models in string theory,Gauge-gravity correspondence},
number = {11},
title = {{A natural language for AdS/CFT correlators}},
volume = {2011},
year = {2011}
}
@article{Woon1997,
abstract = {The method analytic continuation of operators acting integer n-times to complex s-times (hep-th/9707206) is applied to an operator that generates Bernoulli numbers B{\_}n (Math. Mag. 70(1), 51 (1997)). B{\_}n and Bernoulli polynomials B{\_}n(s) are analytic continued to B(s) and B{\_}s(z). A new formula for the Riemann zeta function zeta(s) in terms of nested series of zeta(n) is derived. The new concept of dynamics of the zeros of analytic continued polynomials is introduced, and an interesting phenonmenon of `scatterings' of the zeros of B{\_}s(z) is observed.},
archivePrefix = {arXiv},
arxivId = {physics/9705021},
author = {Woon, S. C.},
eprint = {9705021},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/9705021.pdf:pdf},
number = {1},
primaryClass = {physics},
title = {{Analytic Continuation of Bernoulli Numbers, a New Formula for the Riemann Zeta Function, and the Phenonmenon of Scattering of Zeros}},
url = {http://arxiv.org/abs/physics/9705021},
volume = {70},
year = {1997}
}
@article{Sameshima2019,
author = {Sameshima, Ray Daniel},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/On Different Parametrizations of Feynman Integrals.pdf:pdf},
title = {{On Different Parametrizations of Feynman Integrals How does access to this work benefit you ? Let us know ! On Different Parametrizations of Feynman Integrals}},
year = {2019}
}
@phdthesis{Peasgood2009,
author = {Peasgood, Richard Jason},
file = {:C$\backslash$:/Users/ben/Downloads/A Method to Symbolically Compute Convolution Integrals.pdf:pdf},
title = {{A Method to Symbolically Compute Convolution Integrals by}},
year = {2009}
}
@article{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
eprint = {1412.6980},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1412.6980.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--15},
title = {{Adam: A method for stochastic optimization}},
year = {2015}
}
@article{Antipova2007,
author = {Antipova, I A},
doi = {10.1070/rm2007v062n05abeh004459},
issn = {0036-0279},
journal = {Russian Mathematical Surveys},
number = {5},
pages = {977--979},
publisher = {IOP Publishing},
title = {{Inversion of multidimensional Mellin transforms}},
url = {http://dx.doi.org/10.1070/RM2007v062n05ABEH004459},
volume = {62},
year = {2007}
}
@article{Bytev2020,
abstract = {We consider the derivatives of Horn hypergeometric functions of any number of variables with respect to their parameters. The derivative of such a function of n variables is expressed as a Horn hypergeometric series of n+1 infinite summations depending on the same variables and with the same region of convergence as for the original Horn hypergeometric function. The derivatives of Appell functions, generalized hypergeometric functions, confluent and non-confluent Lauricella series, and generalized Lauricella series are explicitly presented. Applications to the calculations of Feynman diagrams are discussed, especially the series expansions in ϵ within dimensional regularization. Connections with other classes of special functions are discussed as well.},
author = {Bytev, Vladimir V. and Kniehl, Bernd A.},
doi = {10.1016/j.nuclphysb.2019.114911},
file = {:C$\backslash$:/Users/ben/Downloads/1-s2.0-S0550321319303979-main.pdf:pdf},
issn = {05503213},
journal = {Nuclear Physics B},
pages = {114911},
publisher = {Elsevier B.V.},
title = {{Derivatives of any Horn-type hypergeometric functions with respect to their parameters}},
url = {https://doi.org/10.1016/j.nuclphysb.2019.114911},
volume = {952},
year = {2020}
}
@article{vanDerMaaten2008,
author = {van der Maaten, Laurens and Hinton, Geoffrey},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality{\_}reduction tSNE visualization},
pages = {2579--2605},
title = {{Visualizing Data using {\{}t-SNE{\}}}},
url = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
volume = {9},
year = {2008}
}
@article{Thakur1991,
author = {Thakur, Dinesh S},
doi = {10.2307/2944332},
issn = {0003486X},
journal = {Annals of Mathematics},
number = {1},
pages = {25--64},
publisher = {Annals of Mathematics},
title = {{Gamma Functions for Function Fields and Drinfeld Modules}},
url = {http://www.jstor.org/stable/2944332},
volume = {134},
year = {1991}
}
@article{Passare1996,
abstract = {We give a representation, in terms of iterated Mellin-Barnes integrals, of periods on multi-moduli Calabi-Yau manifolds arising in superstring theory. Using this representation and the theory of multi-dimensional residues, we present a method for analytic continuation of the fundamental period in the form of a Horn series.},
archivePrefix = {arXiv},
arxivId = {hep-th/9609215},
author = {Passare, M. and Tsikh, A. K. and Cheshel, A. A.},
doi = {10.1007/BF02073871},
eprint = {9609215},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/9609215.pdf:pdf},
issn = {00405779},
journal = {Theoretical and Mathematical Physics},
number = {3},
pages = {1544--1555},
primaryClass = {hep-th},
title = {{Multiple Mellin-Barnes integrals as periods of Calabi-Yau manifolds with several moduli}},
volume = {109},
year = {1996}
}
@article{Rathie1997,
author = {Rathie, Arjun K},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1206.0350.pdf:pdf},
journal = {Le Matematiche},
number = {2},
pages = {297--310},
title = {{A New Generalization of Generalized Hypergeometric Functions}},
volume = {52},
year = {1997}
}
@article{Zsohar2012,
abstract = {The generalized method of moments (GMM) is the centrepiece of semiparametric estimation frameworks. After putting GMM into context and familiarizing the reader with the main principles behind the method, we discuss the estimation procedure and the properties of the GMM estimator in details. We also provide a short survey of recent research areas in the field. To facili-tate understanding, most concepts are illustrated by simple examples. Econometric analysis begins with some economic phenomenon that is of in-terest to us that we intend to analyse. First we turn to economic theory to see what insights it can offer. It postulates an explanation in some sort of conditions that de-scribe the phenomena in terms of the key economic variables and model parame-ters. However, to answer specific questions, we have to quantify the parameters in-volved. We would like to adopt an estimation method whose implementation does not require the imposition of additional restrictions to the data generating process beyond those implied by the economic model. If it turns out that just for the pur-pose of getting these estimates we have to place further restrictions and make more assumptions and these are found to be unjustified by theory or inappropriate for the data then we run the risk that the invalidity will undermine all our subsequent in-ferences about the phenomenon of our interest. We would like to use a method of statistical estimation that fits well with exactly the kind of information we are get-ting out of our economic models. But what form does that information take? Very often restrictions implied by economic theory take the form what we will refer to as population moment conditions. The generalized method of moments (GMM) is a statistical method that combines observed economic data with the information in population moment conditions to produce estimates of the unknown parameters of this economic model. Once we have those parameters, we can go back to perform inference about the basic question that is of interest to us. Shortly we will see that GMM is very well tailored exactly to the kind of information we are getting out from our economic models. The purpose of this article is to provide an introduction to the GMM frame-work and to give a rough picture of current on-going issues in the field. There are excellent textbooks and reference books available on the topic which are more precise and elaborate in all aspects like M{\'{a}}ty{\'{a}}s [1999] or Hall [2005]. We will heavily rely on them and the interested reader is encouraged to study them. Our treatment misses many details but all simplifications were made to facilitate easy understanding. After introducing the principle of the method of moments in Section 2, we show how to generalize the idea into GMM in Section 3. In Section 4 we discuss the properties of the GMM estimator. The estimation procedure is described in Section 5, while Section 6 provides a short description of testing in the GMM framework. We will also address briefly the question of moment selection in Sec-tion 7. After a short survey of the recent research in Section 8, Section 9 con-cludes.},
author = {Zsohar, Peter},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/2012{\_}K16{\_}150.pdf:pdf},
journal = {Hungarian Statistical Review},
number = {16},
pages = {150--170},
title = {{Short introduction to the generalized method of moments}},
url = {https://www.ksh.hu/statszemle{\_}archive/2012/2012{\_}K16/2012{\_}K16{\_}150.pdf},
volume = {Special},
year = {2012}
}
@article{Gonzalez2015,
abstract = {Ramanujan's Master Theorem is a technique developed by S. Ramanujan to evaluate a class of definite integrals. This technique is used here to produce the values of integrals associated with Feynman diagrams.},
archivePrefix = {arXiv},
arxivId = {1103.0588},
author = {Gonzalez, Ivan and Moll, Victor H. and Schmidt, Ivan},
doi = {10.1016/j.aam.2014.10.001},
eprint = {1103.0588},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1103.0588.pdf:pdf},
issn = {10902074},
journal = {Advances in Applied Mathematics},
keywords = {Definite integrals,Feynman diagrams,Hypergeometric functions},
pages = {214--230},
title = {{Ramanujan's Master Theorem applied to the evaluation of Feynman diagrams}},
volume = {63},
year = {2015}
}
@article{Gonzalez2010,
abstract = {A new heuristic method for the evaluation of definite integrals is presented. This method of brackets has its origin in methods developed for the evaluation of Feynman diagrams. We describe the operational rules and illustrate the method with several examples. The method of brackets reduces the evaluation of a large class of definite integrals to the solution of a linear system of equations. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0812.3356},
author = {Gonzalez, Ivan and Moll, Victor H.},
doi = {10.1016/j.aam.2009.11.003},
eprint = {0812.3356},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/0812.3356.pdf:pdf},
issn = {01968858},
journal = {Advances in Applied Mathematics},
keywords = {Definite integrals,Feynman diagrams,Hypergeometric functions},
number = {1},
pages = {50--73},
title = {{Definite integrals by the method of brackets. Part 1}},
volume = {45},
year = {2010}
}
@article{Rathie2013,
abstract = {In general, while obtaining the probability density function of sums and products of shifted random variables, ordinary analytical methods such as Fourier and Mellin transforms tend to provide integrals which cannot be expressed in terms of ordinary Meijer G and H functions. This way, the need of defining new functions which easily enable one to write such integrals in a closed-form is inherent to the development of this area of statistical sciences. By generalizing the Mellin transform which defines the H function, a new function is established. A direct application of the so-called {\$}\backslashwidehat{\{}I{\}}{\$} is discussed while developing the probability density function of the sum and the product of shifted generalized gamma random variables. Important special cases of the {\$}\backslashwidehat{\{}I{\}}{\$} and their applications in science are also discussed in order to show the applicability of the function hereby defined.},
archivePrefix = {arXiv},
arxivId = {1302.2954},
author = {Rathie, Pushpa N. and Rathie, Arjun K. and Ozelim, Luan C. de S. M.},
eprint = {1302.2954},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1302.2954.pdf:pdf},
keywords = {2000 mathematics subject classification,33c70,33e20,33f05,62e15,62p99,fourier transform,generalized gamma distribution,generalized h function,mellin transform,shifted random variables},
pages = {1--9},
title = {{On the Distribution of the Product and the Sum of Generalized Shifted Gamma Random Variables}},
url = {http://arxiv.org/abs/1302.2954},
year = {2013}
}
@article{Rathie2018,
abstract = {Using generalized hypergeometric functions to perform symbolic manipulations of equations is of great importance to pure and applied scientists. There are in the literature a great number of identities for the Meijer-G function. On the other hand, when more complex expressions arise, that function is not capable of representing them. The H-function is an alternative to overcome this issue, as it is a generalization of the Meijer-G function. In the present paper, a new identity for the H-function is derived. In short, this result enables one to split a particular H-function into the sum of two other H-functions. The new relation in addition to an old result are applied to the summation of hypergeometric series. Finally, some relations between H-functions and elementary functions are built.},
archivePrefix = {arXiv},
arxivId = {1702.03985},
author = {Rathie, Arjun Kumar and Ozelim, Luan Carlos de Sena Monteiro and Rathie, Pushpa Narayan},
doi = {10.3906/mat-1705-48},
eprint = {1702.03985},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1702.03985.pdf:pdf},
issn = {13036149},
journal = {Turkish Journal of Mathematics},
keywords = {H-function,Hypergeometric sum,Identity},
number = {3},
pages = {924--935},
title = {{On a new identity for the H-function with applications to the summation of hypergeometric series}},
volume = {42},
year = {2018}
}
@article{Gonzalez2015a,
abstract = {Ramanujan's Master Theorem is a technique developed by S. Ramanujan to evaluate a class of definite integrals. This technique is used here to produce the values of integrals associated with Feynman diagrams.},
archivePrefix = {arXiv},
arxivId = {1103.0588},
author = {Gonzalez, Ivan and Moll, Victor H. and Schmidt, Ivan},
doi = {10.1016/j.aam.2014.10.001},
eprint = {1103.0588},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1-s2.0-S0196885814001249-main.pdf:pdf},
issn = {10902074},
journal = {Advances in Applied Mathematics},
keywords = {Definite integrals,Feynman diagrams,Hypergeometric functions},
pages = {214--230},
publisher = {Elsevier Inc.},
title = {{Ramanujan's Master Theorem applied to the evaluation of Feynman diagrams}},
url = {http://dx.doi.org/10.1016/j.aam.2014.10.001},
volume = {63},
year = {2015}
}
@article{Geenens2017,
abstract = {Nonparametric kernel density estimation is a very natural procedure which simply makes use of the smoothing power of the convolution operation. Yet, it performs poorly when the density of a positive variable is to be estimated (boundary issues, spurious bumps in the tail). So various extensions of the basic kernel estimator allegedly suitable for R+-supported densities, such as those using Gamma or other asymmetric kernels, abound in the literature. Those, however, are not based on any valid smoothing operation analogous to the convolution, which typically leads to inconsistencies. By contrast, in this paper a kernel estimator for R+-supported densities is defined by making use of the Mellin convolution, the natural analogue of the usual convolution on R+. From there, a very transparent theory flows and leads to new type of asymmetric kernels strongly related to Meijer's {\$}G{\$}-functions. The numerous pleasant properties of this `Mellin-Meijer-kernel density estimator' are demonstrated in the paper. Its pointwise and {\$}L{\_}2{\$}-consistency (with optimal rate of convergence) is established for a large class of densities, including densities unbounded at 0 and showing power-law decay in their right tail. Its practical behaviour is investigated further through simulations and some real data analyses.},
archivePrefix = {arXiv},
arxivId = {1707.04301},
author = {Geenens, Gery},
eprint = {1707.04301},
file = {:C$\backslash$:/Users/ben/Desktop/Mellin Refs/1707.04301.pdf:pdf},
month = {jul},
title = {{Mellin-Meijer-kernel density estimation on R+}},
url = {http://arxiv.org/abs/1707.04301},
year = {2017}
}
@article{Conduit2017,
abstract = {A new computational tool has been developed to model, discover, and optimize new alloys that simultaneously satisfy up to eleven physical criteria. An artificial neural network is trained from pre-existing materials data that enables the prediction of individual material properties both as a function of composition and heat treatment routine, which allows it to optimize the material properties to search for the material with properties most likely to exceed a target criteria. We design a new polycrystalline nickel-base superalloy with the optimal combination of cost, density, $\gamma$′ phase content and solvus, phase stability, fatigue life, yield stress, ultimate tensile strength, stress rupture, oxidation resistance, and tensile elongation. Experimental data demonstrates that the proposed alloy fulfills the computational predictions, possessing multiple physical properties, particularly oxidation resistance and yield stress, that exceed existing commercially available alloys.},
archivePrefix = {arXiv},
arxivId = {arXiv:1803.03039v1},
author = {Conduit, B.D. and Jones, N.G. and Stone, H.J. and Conduit, G.J.},
doi = {10.1016/j.matdes.2017.06.007},
eprint = {arXiv:1803.03039v1},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/1803.03039.pdf:pdf},
issn = {02641275},
journal = {Materials {\&} Design},
keywords = {Materials design,Neural network,Nickel-base superalloy},
month = {oct},
pages = {358--365},
title = {{Design of a nickel-base superalloy using a neural network}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0264127517305907},
volume = {131},
year = {2017}
}
@article{Tresp1994,
author = {Tresp, Volker and Ahmad, Subutai and Neuneier, Ralph},
doi = {10.1.1.23.6971},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/10.1.1.23.6971.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
keywords = {Tresp},
mendeley-tags = {Tresp},
title = {{Training Neural Networks with Deficient Data}},
volume = {6},
year = {1994}
}
@article{Breiman2001,
author = {Breiman, Leo},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Breiman2001{\_}Article{\_}RandomForests.pdf:pdf},
journal = {Machine Learning},
keywords = {Brieman,classification,ensemble,regression},
mendeley-tags = {Brieman},
pages = {5--32},
title = {{Random Forests}},
volume = {45},
year = {2001}
}
@article{Groothuis-oudshoorn2011,
author = {Groothuis-oudshoorn, Karin},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/v45i03.pdf:pdf},
keywords = {chained equations,fully conditional specification,gibbs sampler,mice,multiple imputation,passive imputation,predictor selection,r},
number = {3},
title = {{mice : Multivariate Imputation by Chained}},
volume = {45},
year = {2011}
}
@article{Rubin1976,
author = {Rubin, D. B.},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Rubin Inference and Missing Data.pdf:pdf},
journal = {Biometrika},
keywords = {Rubin},
number = {3},
pages = {581--592},
title = {{Inference and Missing Data}},
volume = {63},
year = {1976}
}
@article{Whitehead2019,
abstract = {We describe a novel deep learning neural network method and its application to impute assay pIC 50 values. Unlike conventional machine learning approaches, this method is trained on sparse bioactivity data as input, typical of that found in public and commercial databases, enabling it to learn directly from correlations between activities measured in dierent assays. In two case studies on public domain data sets we show that the neural network method outperforms traditional quantitative structure-activity relationship (QSAR) models and other leading approaches. Furthermore, by focussing on only the most condent predictions the accuracy is increased to R 2 {\textgreater} 0.9 using our method, as compared to R 2 = 0.43 using the leading prole-QSAR approach. 1 Introduction Accurate compound bioactivity and property data are the foundations of decisions on the selection of hits as the starting point for discovery projects, or the progression of compounds through hit to lead and lead optimisation to candidate selection. However, in practice, the experimental data available on potential compounds of interest are sparse. High-throughput screens may be run on a large screening collections , but these are costly, and thus applied infrequently, and the throughput of an assay usually comes with a trade-o against the quality of the measured data. As discovery projects progress and new compounds are synthesised, the increasing cost of generating high-quality data means that only the most promising compounds are advanced to these late-stage studies. If one considers all of the compounds in a large pharmaceutical company's corporate collection and the assay endpoints that have been measured, only a small fraction of the possible compound-assay combinations have been measured in practice. Public domain databases are also sparsely populated; for example, the ChEMBL 1,2 data set is just 0.05{\%} compete. The implication of this is that a vast trove of information would be revealed if only a small fraction of these missing data could be lled in with high-quality results in a cost-eective way. New hits for projects targeting existing biological targets of interest and high-quality compounds, overlooked during optimi-sation projects, could be identied. Furthermore , compounds with results from early assays could be selected for progression with greater condence if downstream results could be accurately predicted. A common approach for prediction of compound bioactivities is the development of quantitative structure-activity relationship (QSAR) 1},
author = {Whitehead, T. M. and Irwin, B. W.J. and Hunt, P. and Segall, M. D. and Conduit, G. J.},
doi = {10.1021/acs.jcim.8b00768},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/acs.jcim.8b00768.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {3},
pages = {1197--1204},
publisher = {American Chemical Society},
title = {{Imputation of Assay Bioactivity Data Using Deep Learning}},
volume = {59},
year = {2019}
}
@article{Lusci2013,
abstract = {Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal ( cdb.ics.uci.edu ) together with additional material.},
author = {Lusci, Alessandro and Pollastri, Gianluca and Baldi, Pierre},
doi = {10.1021/ci400187y},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci400187y.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {7},
pages = {1563--1575},
title = {{Deep architectures and deep learning in chemoinformatics: The prediction of aqueous solubility for drug-like molecules}},
volume = {53},
year = {2013}
}
@article{Gu2013,
abstract = { The second development program developed in this work was introduced to obtain physicochemical properties of DPP-IV inhibitors. Based on the computation of molecular descriptors, a two-stage feature selection method called mRMR-BFS (minimum redundancy maximum relevance-backward feature selection) was adopted. Then, the support vector regression (SVR) was used in the establishment of the model to map DPP-IV inhibitors to their corresponding inhibitory activity possible. The squared correlation coefficient for the training set of LOOCV and the test set are 0.815 and 0.884, respectively. An online server for predicting inhibitory activity pIC 50 of the DPP-IV inhibitors as described in this paper has been given in the introduction. },
author = {Gu, Tianhong and Yang, Xiaoyan and Li, Minjie and Wu, Milin and Su, Qiang and Lu, Wencong and Zhang, Yuhui},
doi = {10.1155/2013/798743},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/BMRI2013-798743.pdf:pdf},
issn = {23146133},
journal = {BioMed Research International},
number = {August 2014},
title = {{Predicting the DPP-IV inhibitory activity pIC50 based on their physicochemical properties}},
volume = {2013},
year = {2013}
}
@article{Singh2008,
author = {Singh, Ajit P and Gordon, Geoffrey J},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/singh-gordon-kdd-factorization.pdf:pdf},
isbn = {9781605581934},
title = {{Relational Learning via Collective Matrix Factorization Categories and Subject Descriptors}},
year = {2008}
}
@article{Cortes-Ciriano2019,
author = {Cort{\'{e}}s-Ciriano, Isidro and Bender, Andreas},
doi = {10.1021/acs.jcim.9b00297},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/Errors{\_}in{\_}NNs.pdf:pdf},
issn = {1549-9596},
journal = {Journal of Chemical Information and Modeling},
month = {jul},
number = {7},
pages = {3330--3339},
title = {{Reliable Prediction Errors for Deep Neural Networks Using Test-Time Dropout}},
url = {http://pubs.acs.org/doi/10.1021/acs.jcim.9b00297},
volume = {59},
year = {2019}
}
@article{Mayr2018,
abstract = {The to date largest comparative study of nine state-of-the-art drug target prediction methods finds that deep learning outperforms all other competitors. The results are based on a benchmark of 1300 assays and half a million compounds.},
author = {Mayr, Andreas and Klambauer, G{\"{u}}nter and Unterthiner, Thomas and Steijaert, Marvin and Wegner, J{\"{o}}rg K. and Ceulemans, Hugo and Clevert, Djork-Arn{\'{e}} and Hochreiter, Sepp},
doi = {10.1039/C8SC00148K},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/c8sc00148k.pdf:pdf},
isbn = {4373224684},
issn = {2041-6520},
journal = {Chemical Science},
number = {24},
pages = {5441--5451},
title = {{Large-scale comparison of machine learning methods for drug target prediction on ChEMBL}},
url = {http://xlink.rsc.org/?DOI=C8SC00148K},
volume = {9},
year = {2018}
}
@article{Ma2015,
abstract = {Neural networks were widely used for quantitative structure-activity relationships (QSAR) in the 1990s. Because of various practical issues (e.g., slow on large problems, difficult to train, prone to overfitting, etc.), they were superseded by more robust methods like support vector machine (SVM) and random forest (RF), which arose in the early 2000s. The last 10 years has witnessed a revival of neural networks in the machine learning community thanks to new methods for preventing overfitting, more efficient training algorithms, and advancements in computer hardware. In particular, deep neural nets (DNNs), i.e. neural nets with more than one hidden layer, have found great successes in many applications, such as computer vision and natural language processing. Here we show that DNNs can routinely make better prospective predictions than RF on a set of large diverse QSAR data sets that are taken from Merck's drug discovery effort. The number of adjustable parameters needed for DNNs is fairly large, but our results show that it is not necessary to optimize them for individual data sets, and a single set of recommended parameters can achieve better performance than RF for most of the data sets we studied. The usefulness of the parameters is demonstrated on additional data sets not used in the calibration. Although training DNNs is still computationally intensive, using graphical processing units (GPUs) can make this issue manageable.},
author = {Ma, Junshui and Sheridan, Robert P. and Liaw, Andy and Dahl, George E. and Svetnik, Vladimir},
doi = {10.1021/ci500747n},
file = {:C$\backslash$:/Users/ben/Desktop/Mendeley/ci500747n.pdf:pdf},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
number = {2},
pages = {263--274},
title = {{Deep neural nets as a method for quantitative structure-activity relationships}},
volume = {55},
year = {2015}
}
